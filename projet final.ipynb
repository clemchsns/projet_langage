{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Margaux Bailleul 21906121 \\\n",
    "Clémence CHESNAIS 21901191"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sujet : Analyse de sentiments des avis des lecteurs sur des livres "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons souhaité travailler sur la classification d’avis de livres car nous avons toutes les deux un attrait pour la lecture. Il nous a paru évident de travailler sur un sujet qui nous passionne car cela amène une dimension personnelle au projet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choix de la base de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au départ, nous avons souhaité utiliser une API pour récupérer les données nécessaires à notre analyse et construire nous même notre base de données. Pour cela, nous nous sommes orientées vers des sites et applications tels que GoodReads, Google livres, Openlibrary, API fnac ou encore API Amazon. Cependant, nous avons rencontré des difficultés dans la création des clés d’API. En effet, la plupart des accès étaient payants ou, dans le cas de GoodReads, la création de clés n'était plus possible depuis 2020.\n",
    "\n",
    "Notre choix s'est donc orienté vers des bases de données déjà construites. Le site Kaggle dispose d’un nombre conséquent de base de données très variées. Après quelques recherches, nous avons eu le choix entre deux bases de données sur les avis de lecteurs : “French Book review” et “Amazon Books Reviews”. Cependant, cette dernière possède un nombre très important de lignes (environ 3 millions), ce qui nous a empêché de travailler sur celle-ci. En effet, nous avons fait le choix de travailler avec GitHub pour se partager plus facilement les codes. Or, le fichier étant trop lourd, il nous a été impossible de s’envoyer et de se partager le code. Malgré la richesse de cette base de données, le traitement aurait pris un temps trop conséquent.\n",
    "\n",
    "Ainsi, nous avons retenu la base de données “French Book Review”, sur des avis (français) de livre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons importer tous les modules que nous allons utiliser au cours de ce projet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import regex as re\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.snowball import FrenchStemmer \n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous installons la dernière version de spacy ainsi que le modèle de langue française. \\\n",
    "Nous créons ensuite une variable nlp qui nous permet de charger le modèle de langue française préalablement téléchargé. La variable nlp devient un objet de traitement spaCy configuré pour le français."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\clemc\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy) (0.3.3)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Collecting fr-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl (16.3 MB)\n",
      "     ---------------------------------------- 0.0/16.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/16.3 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/16.3 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/16.3 MB 131.3 kB/s eta 0:02:04\n",
      "     --------------------------------------- 0.0/16.3 MB 187.9 kB/s eta 0:01:27\n",
      "     --------------------------------------- 0.1/16.3 MB 297.7 kB/s eta 0:00:55\n",
      "      --------------------------------------- 0.3/16.3 MB 1.4 MB/s eta 0:00:12\n",
      "     -- ------------------------------------- 1.1/16.3 MB 4.4 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 2.5/16.3 MB 8.4 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 3.7/16.3 MB 10.3 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 5.5/16.3 MB 13.0 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 7.2/16.3 MB 15.8 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 8.8/16.3 MB 17.5 MB/s eta 0:00:01\n",
      "     ------------------------ -------------- 10.3/16.3 MB 29.7 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 12.2/16.3 MB 36.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 13.5/16.3 MB 36.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 15.2/16.3 MB 34.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  16.3/16.3 MB 36.4 MB/s eta 0:00:01\n",
      "     --------------------------------------  16.3/16.3 MB 36.4 MB/s eta 0:00:01\n",
      "     --------------------------------------- 16.3/16.3 MB 26.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from fr-core-news-sm==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.3.3)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\clemc\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install -U spacy\n",
    "!python -m spacy download fr_core_news_sm\n",
    "import spacy\n",
    "nlp = spacy.load('fr_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous importons notre jeu de données qui s'intitule 'french_books_reviews.csv' puis nous visualisons ses 5 premières lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>book_title</th>\n",
       "      <th>author</th>\n",
       "      <th>reader_review</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Le Démon de la Colline aux Loups</td>\n",
       "      <td>Dimitri Rouchon-Borie</td>\n",
       "      <td>Ce n'est pas le premier roman à aborder les th...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Simple</td>\n",
       "      <td>Marie-Aude Murail</td>\n",
       "      <td>Simple, alias Barnabé, est un jeune homme de 2...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>La plus secrète mémoire des hommes</td>\n",
       "      <td>Mohamed Mbougar Sarr</td>\n",
       "      <td>Pour écrire La plus secrète mémoire des hommes...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Trancher</td>\n",
       "      <td>Amélie Cordonnier</td>\n",
       "      <td>« La violence d'Aurélien est revenue. Par la f...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>La guerre d'Alan, tome 2</td>\n",
       "      <td>Emmanuel Guibert</td>\n",
       "      <td>Dans ce second album de La Guerre d’Alan, Emma...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                          book_title                 author  \\\n",
       "0           0    Le Démon de la Colline aux Loups  Dimitri Rouchon-Borie   \n",
       "1           1                              Simple      Marie-Aude Murail   \n",
       "2           2  La plus secrète mémoire des hommes   Mohamed Mbougar Sarr   \n",
       "3           3                            Trancher      Amélie Cordonnier   \n",
       "4           4            La guerre d'Alan, tome 2       Emmanuel Guibert   \n",
       "\n",
       "                                       reader_review  rating  label  \n",
       "0  Ce n'est pas le premier roman à aborder les th...     5.0      1  \n",
       "1  Simple, alias Barnabé, est un jeune homme de 2...     4.0      1  \n",
       "2  Pour écrire La plus secrète mémoire des hommes...     4.0      1  \n",
       "3  « La violence d'Aurélien est revenue. Par la f...     3.5      0  \n",
       "4  Dans ce second album de La Guerre d’Alan, Emma...     5.0      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('french_books_reviews.csv', sep=',')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce jeu de données nous disposons de 3 variables qualitatives et 2 variables quantitatives. \n",
    "Pour notre étude, nous avons le titre du livre, les noms et prénoms des auteurs, l'avis du lecteur, la note qu'il a attribué au livre ainsi qu'un label correspondant à la polarité de l'avis. Si l'avis est positif, le label vaut 1, s'il est neutre, il vaut 0 et s'il est négatif, il vaut -1. \\\n",
    "Notons que les noms des livres ainsi que les commentaires sont bien en français."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Statistiques descriptives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, nous commençons par regarder si la base de données contient des valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"reader_review\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13 lignes contiennent des valeurs manquantes. Nous décidons de les supprimer car elles ne représentent que 0.1% de la base de données.\n",
    "De plus, nous souhaitons étudier les avis des clients, il n'y a donc pas d'intérêt à garder les lignes où il n'y a pas d'avis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['reader_review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous vérifions qu'il ne reste plus de ligne sans avis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"reader_review\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous regardons maintenant le nombre d'avis pour chacune des polarités."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_reviews</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nb_reviews\n",
       "class            \n",
       " 1           6658\n",
       " 0           2129\n",
       "-1            858"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"].value_counts()\n",
    "\n",
    "polarity_distribution= (pd.DataFrame.from_dict(Counter(data.label.values),\n",
    "                                             orient='index')\n",
    "                                  .rename(columns={0: 'nb_reviews'}))\n",
    "polarity_distribution.index.name = 'class'\n",
    "polarity_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce jeu de données, il y a 6658 positifs, 2129 neutres et 858 négatifs.\n",
    "\n",
    "Ensuite, nous allons calculer le pourcentage d'avis pour chaque polarité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_reviews</th>\n",
       "      <th>pourcentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6658</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2129</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>858</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nb_reviews  pourcentage\n",
       "class                         \n",
       " 1           6658         0.69\n",
       " 0           2129         0.22\n",
       "-1            858         0.09"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarity_distribution['pourcentage'] = np.around(polarity_distribution.nb_reviews /\n",
    "                                                np.sum(polarity_distribution.nb_reviews),\n",
    "                                                2)\n",
    "polarity_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous représentons sur un graphique la distributions des polarités selon le nombre d'avis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': \"Nombre d'avis par classe\"}, xlabel='class'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAq0AAAIhCAYAAABkLoMIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA5aElEQVR4nO3df1zV9f3///sZvwSEo6BwINHIyDCtDA2hHBT+THKtvaeLRlrmj/w1Vn405lLz7SBd+aPYTF2ppWa9t+msFdO0XCooWlSaWi01TQ+a4UEdguLr+0cXX9+OIIo/4KndrpfLuVze5/V6nHOeL4J5e7988dJhWZYlAAAAwGA/aegFAAAAAOdCtAIAAMB4RCsAAACMR7QCAADAeEQrAAAAjEe0AgAAwHhEKwAAAIxHtAIAAMB4RCsAAACMR7QC8DJ//nw5HA41atRIu3fvrrY/NTVV7dq1a4CVSQMGDFDjxo0b5LPPxeFwaOLEifbz01/Hy2nAgAG69tprL+tnmCY1NVWpqakNvQwADYBoBVCjiooK/f73v2/oZaAWTz31lJYuXdrQywCAekG0AqhRz549tXjxYn388ccNvZRLwrIslZeXN/QyLqnWrVurQ4cODb2M81ZVVaWKioqGXgaAKxTRCqBGY8aMUXh4uMaOHXvO2ePHjys7O1uxsbHy9/fXNddco+HDh+vw4cNec9dee63S09P11ltvqUOHDgoMDFR8fLzeeustSd//lXp8fLyCg4N1++23a9OmTTV+3tatW5WWlqbg4GA1b95cI0aM0H//+1+vGYfDoREjRujFF19UfHy8AgICtGDBAknSF198oYyMDEVERCggIEDx8fH605/+dF5fl7KyMg0aNEjh4eFq3Lixevbsqc8///y8Xvv666+re/fuioqKso/9ySef1LFjx+yZGTNmyOFw6Msvv6z2+rFjx8rf31/ffvutpJovD/i///s/JSYmyul0KigoSNddd50eeeSRc67t9Ndr9uzZuuGGGxQQEKC2bdtqyZIlXnMHDx7UsGHD1LZtWzVu3FgRERG6++679cEHH3jN7dq1Sw6HQ1OnTtXkyZMVGxurgIAAvffee2ddw6lTp/TCCy/o1ltvVWBgoJo0aaLOnTtr+fLlta796aefVmJiosLCwhQaGqrbbrtNL730kizL8ppbvXq1UlNTFR4ersDAQLVs2VK/+MUvvL53Zs2apVtuuUWNGzdWSEiIbrzxRv3ud7/zeh+3260hQ4aoRYsW8vf3V2xsrJ5++mmdPHmy1nUCuDi+Db0AAGYKCQnR73//e/3mN7/R6tWrdffdd9c4Z1mW7rvvPq1atUrZ2dnq0qWLPvnkE02YMEEFBQUqKChQQECAPf/xxx8rOztb48aNk9Pp1NNPP637779f2dnZWrVqlXJycuRwODR27Filp6dr586dCgwMtF9/4sQJ3XPPPRoyZIiefPJJrV+/XpMnT9bu3bv15ptveq1t2bJl+uCDDzR+/Hi5XC5FRETos88+U3Jyslq2bKnnnntOLpdL//rXvzRq1Ch9++23mjBhwlm/JqePdf369Ro/frw6deqkdevWqVevXtVmBwwYoAEDBnht++KLL3TPPfcoKytLwcHB2r59u6ZMmaKNGzdq9erVkqRf//rXGjt2rObPn6/Jkyfbr62qqtLChQt17733qlmzZjWur6CgQP369VO/fv00ceJE+7rk0+99LsuXL9d7772nSZMmKTg4WH/+85/1wAMPyNfXV//zP/8jSfruu+8kSRMmTJDL5dLRo0e1dOlSpaamatWqVdWuN33++ed1ww036Nlnn1VoaKji4uLO+vkDBgzQwoULNXDgQE2aNEn+/v768MMPtWvXrlrXvWvXLg0ZMkQtW7aUJBUWFmrkyJH65ptvNH78eHumd+/e6tKli15++WU1adJE33zzjfLz81VZWamgoCAtWbJEw4YN08iRI/Xss8/qJz/5ib788kt99tln9me53W7dfvvt+slPfqLx48erdevWKigo0OTJk7Vr1y7NmzfvvL7WAC6ABQA/MG/ePEuSVVRUZFVUVFjXXXed1bFjR+vUqVOWZVlWSkqKddNNN9nz+fn5liRr6tSpXu/z+uuvW5KsOXPm2NtatWplBQYGWnv37rW3FRcXW5KsqKgo69ixY/b2ZcuWWZKs5cuX29v69+9vSbJmzpzp9Vl/+MMfLEnW2rVr7W2SLKfTaX333Xdesz169LBatGhheTwer+0jRoywGjVqVG3+h955551aP3/ChAlnfe2ZTp06ZZ04ccJas2aNJcn6+OOP7X3333+/1aJFC6uqqsre9vbbb1uSrDfffNPe1r9/f6tVq1b282effdaSZB0+fPi813GaJCswMNByu932tpMnT1o33nijdf3115/1dSdPnrROnDhhpaWlWT//+c/t7Tt37rQkWa1bt7YqKyvP+fn//ve/LUnWuHHjap1LSUmxUlJSzrq/qqrKOnHihDVp0iQrPDzc/r7961//akmyiouLz/raESNGWE2aNKn184cMGWI1btzY2r17t9f201/7rVu31vp6ABeOywMAnJW/v78mT56sTZs26Y033qhx5vRZvDPPKv7yl79UcHCwVq1a5bX91ltv1TXXXGM/j4+Pl/T9b4UHBQVV217THQwefPBBr+cZGRmSVO2vnu+++241bdrUfn78+HGtWrVKP//5zxUUFKSTJ0/aj3vuuUfHjx9XYWFhjcf5w/c/2+efy1dffaWMjAy5XC75+PjIz89PKSkpkqRt27bZcw8//LD27t2rd9991942b948uVyuGs/qntapUydJUt++ffXGG2/om2++Oa91nZaWlqbIyEj7uY+Pj/r166cvv/xSe/futbe/+OKLuu2229SoUSP5+vrKz89Pq1at8jqG0/r06SM/P79zfvY777wjSRo+fHid1ix9/z3YtWtXOZ1O++s6fvx4HTp0SAcOHJD0/fedv7+/Bg8erAULFuirr76q9j633367Dh8+rAceeED/+Mc/7Mswfuitt97SXXfdpejoaK/vn9P/XdasWVPn9QM4P0QrgFr96le/0m233aZx48bpxIkT1fYfOnRIvr6+at68udd2h8Mhl8ulQ4cOeW0PCwvzeu7v71/r9uPHj3tt9/X1VXh4uNc2l8tlr+WHoqKiqq315MmTeuGFF+Tn5+f1uOeeeySpxlA581jP9vm1OXr0qLp06aINGzZo8uTJev/991VUVKS///3vkuT1S2K9evVSVFSU/VfNpaWlWr58uR566CH5+Pic9TN++tOfatmyZTp58qQeeughtWjRQu3atdNrr712zvWd7TjO/NpOmzZNjz32mBITE/W3v/1NhYWFKioqUs+ePWv8Rbcz/xuczcGDB+Xj43NeX8sf2rhxo7p37y5Jmjt3rtatW6eioiKNGzdO0v//dW3durXeffddRUREaPjw4WrdurVat26tmTNn2u+VmZmpl19+Wbt379YvfvELRUREKDExUStXrrRnSkpK9Oabb1b7/rnpppsk1f79A+DicE0rgFo5HA5NmTJF3bp105w5c6rtDw8P18mTJ3Xw4EGvcLUsS2632z77d6mcPHlShw4d8gpHt9ttr+XMtf9Q06ZN5ePjo8zMzLOe0YuNjT3rZ58+1rN9fm1Wr16tffv26f3337fPrkqq9stqkuw1Pv/88zp8+LAWL16siooKPfzww+f8nJ/97Gf62c9+poqKChUWFio3N1cZGRm69tprlZSUVOtrazqOM7+2CxcuVGpqqmbNmuU1d+TIkRrf83zvVdu8eXNVVVXJ7Xafd+hK0pIlS+Tn56e33npLjRo1srcvW7as2myXLl3UpUsXVVVVadOmTXrhhReUlZWlyMhI/epXv5L0/Vnuhx9+WMeOHdO///1vTZgwQenp6fr888/VqlUrNWvWTDfffLP+8Ic/1Lie6Ojo8147gLrhTCuAc+ratau6deumSZMm6ejRo1770tLSJH0fMz/0t7/9TceOHbP3X0qLFi3yer548WJJOudN54OCgnTXXXfpo48+0s0336yOHTtWe5wZvj9011131fr5tTkdbz/8pTRJmj17do3zDz/8sI4fP67XXntN8+fPV1JSkm688cZzfs5pAQEBSklJ0ZQpUyRJH3300Tlfs2rVKpWUlNjPq6qq9Prrr6t169Zq0aKFfRxnHsMnn3yigoKC815bTU7/9fqZMXwuDodDvr6+Xmegy8vL9eqrr571NT4+PkpMTLTvGPHhhx9WmwkODlavXr00btw4VVZWauvWrZKk9PR0bdmyRa1bt67x+4doBS4fzrQCOC9TpkxRQkKCDhw4YP9VqCR169ZNPXr00NixY1VWVqY77rjDvntAhw4dlJmZeUnX4e/vr+eee05Hjx5Vp06d7LsH9OrVS3feeec5Xz9z5kzdeeed6tKlix577DFde+21OnLkiL788ku9+eabtf6mfffu3fXTn/5UY8aM0bFjx9SxY0etW7eu1kA6LTk5WU2bNtXQoUM1YcIE+fn5adGiRWe9D+6NN96opKQk5ebmas+ePTWe5T7T+PHjtXfvXqWlpalFixY6fPiwZs6c6XXtbG2aNWumu+++W0899ZR994Dt27d73fYqPT1d//u//6sJEyYoJSVFO3bs0KRJkxQbG3tRt3zq0qWLMjMzNXnyZJWUlCg9PV0BAQH66KOPFBQUpJEjR9b4ut69e2vatGnKyMjQ4MGDdejQIT377LPVwvrFF1/U6tWr1bt3b7Vs2VLHjx/Xyy+/LOn7/6dMkgYNGqTAwEDdcccdioqKktvtVm5urpxOp/03BpMmTdLKlSuVnJysUaNGqU2bNjp+/Lh27dqlt99+Wy+++KId+AAusYb+TTAAZvnh3QPOlJGRYUnyunuAZVlWeXm5NXbsWKtVq1aWn5+fFRUVZT322GNWaWmp11yrVq2s3r17V3tfSdbw4cO9tp3+7fM//vGP9rb+/ftbwcHB1ieffGKlpqZagYGBVlhYmPXYY49ZR48ePed7/vC9H3nkEeuaa66x/Pz8rObNm1vJycnW5MmTa/3aWJZlHT582HrkkUesJk2aWEFBQVa3bt2s7du3n9fdA9avX28lJSVZQUFBVvPmza1HH33U+vDDDy1J1rx586rNz5kzx/6t/jPvdnD66/HDuwe89dZbVq9evaxrrrnG8vf3tyIiIqx77rnH+uCDD855XKe/Xn/+85+t1q1bW35+ftaNN95oLVq0yGuuoqLCGj16tHXNNddYjRo1sm677TZr2bJl1dZS03+/c6mqqrKmT59utWvXzvL397ecTqeVlJTkdceEmu4e8PLLL1tt2rSxAgICrOuuu87Kzc21XnrpJUuStXPnTsuyLKugoMD6+c9/brVq1coKCAiwwsPDrZSUFK+7UyxYsMC66667rMjISMvf39+Kjo62+vbta33yySden3fw4EFr1KhRVmxsrOXn52eFhYVZCQkJ1rhx46p9HwK4dByWdcbdlwEAPzoOh0PDhw9XXl5eQy8FAGrENa0AAAAwHtEKAAAA4/GLWAAAcaUYANNxphUAAADGI1oBAABgPKIVAAAAxrtqr2k9deqU9u3bp5CQkPP+ZwQBAABQfyzL0pEjRxQdHa2f/KT2c6lXbbTu27dPMTExDb0MAAAAnMOePXvO+a/JXbXRGhISIun7L0JoaGgDrwYAAABnKisrU0xMjN1ttblqo/X0JQGhoaFEKwAAgMHO51JOfhELAAAAxiNaAQAAYDyiFQAAAMYjWgEAAGA8ohUAAADGI1oBAABgPKIVAAAAxiNaAQAAYDyiFQAAAMYjWgEAAGA8ohUAAADGI1oBAABgPKIVAAAAxiNaAQAAYDyiFQAAAMYjWgEAAGA8ohUAAADGI1oBAABgPKIVAAAAxvNt6AXg/F375D8begmX1K5nejf0EgAAwBWCM60AAAAwHtEKAAAA4xGtAAAAMB7RCgAAAOMRrQAAADAe0QoAAADjEa0AAAAwHtEKAAAA4xGtAAAAMB7RCgAAAOMRrQAAADAe0QoAAADjEa0AAAAwHtEKAAAA4xGtAAAAMB7RCgAAAOMRrQAAADAe0QoAAADjEa0AAAAwHtEKAAAA4xGtAAAAMB7RCgAAAOMRrQAAADAe0QoAAADjEa0AAAAwHtEKAAAA4xGtAAAAMB7RCgAAAOMRrQAAADAe0QoAAADjEa0AAAAwHtEKAAAA4xGtAAAAMB7RCgAAAOMRrQAAADAe0QoAAADjEa0AAAAwHtEKAAAA49U5Wr/55hv9+te/Vnh4uIKCgnTrrbdq8+bN9n7LsjRx4kRFR0crMDBQqamp2rp1q9d7VFRUaOTIkWrWrJmCg4PVp08f7d2712umtLRUmZmZcjqdcjqdyszM1OHDhy/sKAEAAHBFq1O0lpaW6o477pCfn5/eeecdffbZZ3ruuefUpEkTe2bq1KmaNm2a8vLyVFRUJJfLpW7duunIkSP2TFZWlpYuXaolS5Zo7dq1Onr0qNLT01VVVWXPZGRkqLi4WPn5+crPz1dxcbEyMzMv/ogBAABwxXFYlmWd7/CTTz6pdevW6YMPPqhxv2VZio6OVlZWlsaOHSvp+7OqkZGRmjJlioYMGSKPx6PmzZvr1VdfVb9+/SRJ+/btU0xMjN5++2316NFD27ZtU9u2bVVYWKjExERJUmFhoZKSkrR9+3a1adPmnGstKyuT0+mUx+NRaGjo+R6i0a598p8NvYRLatczvRt6CQAAoAHVpdfqdKZ1+fLl6tixo375y18qIiJCHTp00Ny5c+39O3fulNvtVvfu3e1tAQEBSklJ0fr16yVJmzdv1okTJ7xmoqOj1a5dO3umoKBATqfTDlZJ6ty5s5xOpz1zpoqKCpWVlXk9AAAAcHWoU7R+9dVXmjVrluLi4vSvf/1LQ4cO1ahRo/TKK69IktxutyQpMjLS63WRkZH2PrfbLX9/fzVt2rTWmYiIiGqfHxERYc+cKTc3177+1el0KiYmpi6HBgAAAIPVKVpPnTql2267TTk5OerQoYOGDBmiQYMGadasWV5zDofD67llWdW2nenMmZrma3uf7OxseTwe+7Fnz57zPSwAAAAYrk7RGhUVpbZt23pti4+P19dffy1JcrlcklTtbOiBAwfss68ul0uVlZUqLS2tdaakpKTa5x88eLDaWdzTAgICFBoa6vUAAADA1aFO0XrHHXdox44dXts+//xztWrVSpIUGxsrl8ullStX2vsrKyu1Zs0aJScnS5ISEhLk5+fnNbN//35t2bLFnklKSpLH49HGjRvtmQ0bNsjj8dgzAAAA+PHwrcvwb3/7WyUnJysnJ0d9+/bVxo0bNWfOHM2ZM0fS93+ln5WVpZycHMXFxSkuLk45OTkKCgpSRkaGJMnpdGrgwIF64oknFB4errCwMI0ePVrt27dX165dJX1/9rZnz54aNGiQZs+eLUkaPHiw0tPTz+vOAQAAALi61ClaO3XqpKVLlyo7O1uTJk1SbGysZsyYoQcffNCeGTNmjMrLyzVs2DCVlpYqMTFRK1asUEhIiD0zffp0+fr6qm/fviovL1daWprmz58vHx8fe2bRokUaNWqUfZeBPn36KC8v72KPFwAAAFegOt2n9UrCfVrNx31aAQD4cbts92kFAAAAGgLRCgAAAOMRrQAAADAe0QoAAADjEa0AAAAwHtEKAAAA4xGtAAAAMB7RCgAAAOMRrQAAADAe0QoAAADjEa0AAAAwHtEKAAAA4xGtAAAAMB7RCgAAAOMRrQAAADAe0QoAAADjEa0AAAAwHtEKAAAA4xGtAAAAMB7RCgAAAOMRrQAAADAe0QoAAADjEa0AAAAwHtEKAAAA4xGtAAAAMB7RCgAAAOMRrQAAADAe0QoAAADjEa0AAAAwHtEKAAAA4xGtAAAAMB7RCgAAAOMRrQAAADAe0QoAAADjEa0AAAAwHtEKAAAA4xGtAAAAMB7RCgAAAOMRrQAAADAe0QoAAADjEa0AAAAwHtEKAAAA4xGtAAAAMB7RCgAAAOMRrQAAADAe0QoAAADjEa0AAAAwHtEKAAAA4xGtAAAAMB7RCgAAAOMRrQAAADAe0QoAAADjEa0AAAAwHtEKAAAA4xGtAAAAMF6donXixIlyOBxeD5fLZe+3LEsTJ05UdHS0AgMDlZqaqq1bt3q9R0VFhUaOHKlmzZopODhYffr00d69e71mSktLlZmZKafTKafTqczMTB0+fPjCjxIAAABXtDqfab3pppu0f/9++/Hpp5/a+6ZOnapp06YpLy9PRUVFcrlc6tatm44cOWLPZGVlaenSpVqyZInWrl2ro0ePKj09XVVVVfZMRkaGiouLlZ+fr/z8fBUXFyszM/MiDxUAAABXKt86v8DX1+vs6mmWZWnGjBkaN26c7r//fknSggULFBkZqcWLF2vIkCHyeDx66aWX9Oqrr6pr166SpIULFyomJkbvvvuuevTooW3btik/P1+FhYVKTEyUJM2dO1dJSUnasWOH2rRpczHHCwAAgCtQnc+0fvHFF4qOjlZsbKx+9atf6auvvpIk7dy5U263W927d7dnAwIClJKSovXr10uSNm/erBMnTnjNREdHq127dvZMQUGBnE6nHayS1LlzZzmdTnsGAAAAPy51OtOamJioV155RTfccINKSko0efJkJScna+vWrXK73ZKkyMhIr9dERkZq9+7dkiS32y1/f381bdq02szp17vdbkVERFT77IiICHumJhUVFaqoqLCfl5WV1eXQAAAAYLA6RWuvXr3s/7t9+/ZKSkpS69attWDBAnXu3FmS5HA4vF5jWVa1bWc6c6am+XO9T25urp5++unzOg4AAABcWS7qllfBwcFq3769vvjiC/s61zPPhh44cMA+++pyuVRZWanS0tJaZ0pKSqp91sGDB6udxf2h7OxseTwe+7Fnz56LOTQAAAAY5KKitaKiQtu2bVNUVJRiY2Plcrm0cuVKe39lZaXWrFmj5ORkSVJCQoL8/Py8Zvbv368tW7bYM0lJSfJ4PNq4caM9s2HDBnk8HnumJgEBAQoNDfV6AAAA4OpQp8sDRo8erXvvvVctW7bUgQMHNHnyZJWVlal///5yOBzKyspSTk6O4uLiFBcXp5ycHAUFBSkjI0OS5HQ6NXDgQD3xxBMKDw9XWFiYRo8erfbt29t3E4iPj1fPnj01aNAgzZ49W5I0ePBgpaenc+cAAACAH6k6RevevXv1wAMP6Ntvv1Xz5s3VuXNnFRYWqlWrVpKkMWPGqLy8XMOGDVNpaakSExO1YsUKhYSE2O8xffp0+fr6qm/fviovL1daWprmz58vHx8fe2bRokUaNWqUfZeBPn36KC8v71IcLwAAAK5ADsuyrIZexOVQVlYmp9Mpj8dz1VwqcO2T/2zoJVxSu57p3dBLAAAADaguvXZR17QCAAAA9YFoBQAAgPGIVgAAABiPaAUAAIDxiFYAAAAYj2gFAACA8YhWAAAAGI9oBQAAgPGIVgAAABiPaAUAAIDxiFYAAAAYj2gFAACA8YhWAAAAGI9oBQAAgPGIVgAAABiPaAUAAIDxiFYAAAAYj2gFAACA8YhWAAAAGI9oBQAAgPGIVgAAABiPaAUAAIDxiFYAAAAYj2gFAACA8YhWAAAAGI9oBQAAgPGIVgAAABiPaAUAAIDxiFYAAAAYj2gFAACA8YhWAAAAGI9oBQAAgPGIVgAAABiPaAUAAIDxiFYAAAAYj2gFAACA8YhWAAAAGI9oBQAAgPGIVgAAABiPaAUAAIDxiFYAAAAYj2gFAACA8YhWAAAAGI9oBQAAgPGIVgAAABiPaAUAAIDxiFYAAAAYj2gFAACA8YhWAAAAGI9oBQAAgPGIVgAAABiPaAUAAIDxiFYAAAAYj2gFAACA8YhWAAAAGO+iojU3N1cOh0NZWVn2NsuyNHHiREVHRyswMFCpqanaunWr1+sqKio0cuRINWvWTMHBwerTp4/27t3rNVNaWqrMzEw5nU45nU5lZmbq8OHDF7NcAAAAXKEuOFqLioo0Z84c3XzzzV7bp06dqmnTpikvL09FRUVyuVzq1q2bjhw5Ys9kZWVp6dKlWrJkidauXaujR48qPT1dVVVV9kxGRoaKi4uVn5+v/Px8FRcXKzMz80KXCwAAgCvYBUXr0aNH9eCDD2ru3Llq2rSpvd2yLM2YMUPjxo3T/fffr3bt2mnBggX673//q8WLF0uSPB6PXnrpJT333HPq2rWrOnTooIULF+rTTz/Vu+++K0natm2b8vPz9Ze//EVJSUlKSkrS3Llz9dZbb2nHjh2X4LABAABwJbmgaB0+fLh69+6trl27em3fuXOn3G63unfvbm8LCAhQSkqK1q9fL0navHmzTpw44TUTHR2tdu3a2TMFBQVyOp1KTEy0Zzp37iyn02nPAAAA4MfDt64vWLJkiT788EMVFRVV2+d2uyVJkZGRXtsjIyO1e/due8bf39/rDO3pmdOvd7vdioiIqPb+ERER9syZKioqVFFRYT8vKyurw1EBAADAZHU607pnzx795je/0cKFC9WoUaOzzjkcDq/nlmVV23amM2dqmq/tfXJzc+1f2nI6nYqJian18wAAAHDlqFO0bt68WQcOHFBCQoJ8fX3l6+urNWvW6Pnnn5evr699hvXMs6EHDhyw97lcLlVWVqq0tLTWmZKSkmqff/DgwWpncU/Lzs6Wx+OxH3v27KnLoQEAAMBgdYrWtLQ0ffrppyouLrYfHTt21IMPPqji4mJdd911crlcWrlypf2ayspKrVmzRsnJyZKkhIQE+fn5ec3s379fW7ZssWeSkpLk8Xi0ceNGe2bDhg3yeDz2zJkCAgIUGhrq9QAAAMDVoU7XtIaEhKhdu3Ze24KDgxUeHm5vz8rKUk5OjuLi4hQXF6ecnBwFBQUpIyNDkuR0OjVw4EA98cQTCg8PV1hYmEaPHq327dvbv9gVHx+vnj17atCgQZo9e7YkafDgwUpPT1ebNm0u+qABAABwZanzL2Kdy5gxY1ReXq5hw4aptLRUiYmJWrFihUJCQuyZ6dOny9fXV3379lV5ebnS0tI0f/58+fj42DOLFi3SqFGj7LsM9OnTR3l5eZd6uQAAALgCOCzLshp6EZdDWVmZnE6nPB7PVXOpwLVP/rOhl3BJ7Xqmd0MvAQAANKC69NpF/TOuAAAAQH0gWgEAAGA8ohUAAADGI1oBAABgPKIVAAAAxiNaAQAAYDyiFQAAAMYjWgEAAGA8ohUAAADGI1oBAABgPKIVAAAAxiNaAQAAYDyiFQAAAMYjWgEAAGA8ohUAAADGI1oBAABgPKIVAAAAxiNaAQAAYDyiFQAAAMYjWgEAAGA8ohUAAADGI1oBAABgPKIVAAAAxiNaAQAAYDyiFQAAAMYjWgEAAGA8ohUAAADGI1oBAABgPKIVAAAAxiNaAQAAYDyiFQAAAMYjWgEAAGA8ohUAAADGI1oBAABgPKIVAAAAxiNaAQAAYDyiFQAAAMYjWgEAAGA8ohUAAADGI1oBAABgPKIVAAAAxiNaAQAAYDyiFQAAAMYjWgEAAGA8ohUAAADGI1oBAABgPKIVAAAAxiNaAQAAYDyiFQAAAMYjWgEAAGA8ohUAAADGI1oBAABgPKIVAAAAxiNaAQAAYDyiFQAAAMYjWgEAAGC8OkXrrFmzdPPNNys0NFShoaFKSkrSO++8Y++3LEsTJ05UdHS0AgMDlZqaqq1bt3q9R0VFhUaOHKlmzZopODhYffr00d69e71mSktLlZmZKafTKafTqczMTB0+fPjCjxIAAABXtDpFa4sWLfTMM89o06ZN2rRpk+6++2797Gc/s8N06tSpmjZtmvLy8lRUVCSXy6Vu3brpyJEj9ntkZWVp6dKlWrJkidauXaujR48qPT1dVVVV9kxGRoaKi4uVn5+v/Px8FRcXKzMz8xIdMgAAAK40DsuyrIt5g7CwMP3xj3/UI488oujoaGVlZWns2LGSvj+rGhkZqSlTpmjIkCHyeDxq3ry5Xn31VfXr10+StG/fPsXExOjtt99Wjx49tG3bNrVt21aFhYVKTEyUJBUWFiopKUnbt29XmzZtzmtdZWVlcjqd8ng8Cg0NvZhDNMa1T/6zoZdwSe16pndDLwEAADSguvTaBV/TWlVVpSVLlujYsWNKSkrSzp075Xa71b17d3smICBAKSkpWr9+vSRp8+bNOnHihNdMdHS02rVrZ88UFBTI6XTawSpJnTt3ltPptGdqUlFRobKyMq8HAAAArg51jtZPP/1UjRs3VkBAgIYOHaqlS5eqbdu2crvdkqTIyEiv+cjISHuf2+2Wv7+/mjZtWutMREREtc+NiIiwZ2qSm5trXwPrdDoVExNT10MDAACAoeocrW3atFFxcbEKCwv12GOPqX///vrss8/s/Q6Hw2vesqxq28505kxN8+d6n+zsbHk8HvuxZ8+e8z0kAAAAGK7O0erv76/rr79eHTt2VG5urm655RbNnDlTLpdLkqqdDT1w4IB99tXlcqmyslKlpaW1zpSUlFT73IMHD1Y7i/tDAQEB9l0NTj8AAABwdbjo+7RalqWKigrFxsbK5XJp5cqV9r7KykqtWbNGycnJkqSEhAT5+fl5zezfv19btmyxZ5KSkuTxeLRx40Z7ZsOGDfJ4PPYMAAAAflx86zL8u9/9Tr169VJMTIyOHDmiJUuW6P3331d+fr4cDoeysrKUk5OjuLg4xcXFKScnR0FBQcrIyJAkOZ1ODRw4UE888YTCw8MVFham0aNHq3379urataskKT4+Xj179tSgQYM0e/ZsSdLgwYOVnp5+3ncOAAAAwNWlTtFaUlKizMxM7d+/X06nUzfffLPy8/PVrVs3SdKYMWNUXl6uYcOGqbS0VImJiVqxYoVCQkLs95g+fbp8fX3Vt29flZeXKy0tTfPnz5ePj489s2jRIo0aNcq+y0CfPn2Ul5d3KY4XAAAAV6CLvk+rqbhPq/m4TysAAD9u9XKfVgAAAKC+EK0AAAAwHtEKAAAA4xGtAAAAMB7RCgAAAOMRrQAAADAe0QoAAADjEa0AAAAwHtEKAAAA4xGtAAAAMB7RCgAAAOMRrQAAADAe0QoAAADjEa0AAAAwHtEKAAAA4xGtAAAAMB7RCgAAAOMRrQAAADAe0QoAAADjEa0AAAAwHtEKAAAA4xGtAAAAMB7RCgAAAOMRrQAAADAe0QoAAADjEa0AAAAwHtEKAAAA4xGtAAAAMB7RCgAAAOMRrQAAADAe0QoAAADjEa0AAAAwHtEKAAAA4xGtAAAAMB7RCgAAAOMRrQAAADAe0QoAAADjEa0AAAAwHtEKAAAA4xGtAAAAMB7RCgAAAOMRrQAAADAe0QoAAADjEa0AAAAwHtEKAAAA4xGtAAAAMB7RCgAAAOMRrQAAADAe0QoAAADjEa0AAAAwnm9DLwAALrdrn/xnQy/hktn1TO+GXgIANAjOtAIAAMB4RCsAAACMR7QCAADAeEQrAAAAjFenaM3NzVWnTp0UEhKiiIgI3XfffdqxY4fXjGVZmjhxoqKjoxUYGKjU1FRt3brVa6aiokIjR45Us2bNFBwcrD59+mjv3r1eM6WlpcrMzJTT6ZTT6VRmZqYOHz58YUcJAACAK1qdonXNmjUaPny4CgsLtXLlSp08eVLdu3fXsWPH7JmpU6dq2rRpysvLU1FRkVwul7p166YjR47YM1lZWVq6dKmWLFmitWvX6ujRo0pPT1dVVZU9k5GRoeLiYuXn5ys/P1/FxcXKzMy8BIcMAACAK43DsizrQl988OBBRUREaM2aNfrpT38qy7IUHR2trKwsjR07VtL3Z1UjIyM1ZcoUDRkyRB6PR82bN9err76qfv36SZL27dunmJgYvf322+rRo4e2bdumtm3bqrCwUImJiZKkwsJCJSUlafv27WrTps0511ZWVian0ymPx6PQ0NALPUSjXE237ZG4dQ/qz9X0s8PPDYCrSV167aKuafV4PJKksLAwSdLOnTvldrvVvXt3eyYgIEApKSlav369JGnz5s06ceKE10x0dLTatWtnzxQUFMjpdNrBKkmdO3eW0+m0Z85UUVGhsrIyrwcAAACuDhccrZZl6fHHH9edd96pdu3aSZLcbrckKTIy0ms2MjLS3ud2u+Xv76+mTZvWOhMREVHtMyMiIuyZM+Xm5trXvzqdTsXExFzooQEAAMAwFxytI0aM0CeffKLXXnut2j6Hw+H13LKsatvOdOZMTfO1vU92drY8Ho/92LNnz/kcBgAAAK4AFxStI0eO1PLly/Xee++pRYsW9naXyyVJ1c6GHjhwwD776nK5VFlZqdLS0lpnSkpKqn3uwYMHq53FPS0gIEChoaFeDwAAAFwd6hStlmVpxIgR+vvf/67Vq1crNjbWa39sbKxcLpdWrlxpb6usrNSaNWuUnJwsSUpISJCfn5/XzP79+7VlyxZ7JikpSR6PRxs3brRnNmzYII/HY88AAADgx8O3LsPDhw/X4sWL9Y9//EMhISH2GVWn06nAwEA5HA5lZWUpJydHcXFxiouLU05OjoKCgpSRkWHPDhw4UE888YTCw8MVFham0aNHq3379urataskKT4+Xj179tSgQYM0e/ZsSdLgwYOVnp5+XncOAAAAwNWlTtE6a9YsSVJqaqrX9nnz5mnAgAGSpDFjxqi8vFzDhg1TaWmpEhMTtWLFCoWEhNjz06dPl6+vr/r27avy8nKlpaVp/vz58vHxsWcWLVqkUaNG2XcZ6NOnj/Ly8i7kGAEAAHCFu6j7tJqM+7Saj/tNor5cTT87/NwAuJrU231aAQAAgPpAtAIAAMB4RCsAAACMR7QCAADAeEQrAAAAjEe0AgAAwHhEKwAAAIxHtAIAAMB4RCsAAACMR7QCAADAeEQrAAAAjEe0AgAAwHhEKwAAAIxHtAIAAMB4RCsAAACMR7QCAADAeEQrAAAAjEe0AgAAwHhEKwAAAIxHtAIAAMB4RCsAAACMR7QCAADAeEQrAAAAjEe0AgAAwHhEKwAAAIxHtAIAAMB4RCsAAACMR7QCAADAeEQrAAAAjEe0AgAAwHhEKwAAAIxHtAIAAMB4RCsAAACMR7QCAADAeEQrAAAAjEe0AgAAwHhEKwAAAIxHtAIAAMB4RCsAAACMR7QCAADAeEQrAAAAjEe0AgAAwHhEKwAAAIxHtAIAAMB4RCsAAACMR7QCAADAeEQrAAAAjEe0AgAAwHhEKwAAAIxHtAIAAMB4RCsAAACMR7QCAADAeEQrAAAAjEe0AgAAwHhEKwAAAIxX52j997//rXvvvVfR0dFyOBxatmyZ137LsjRx4kRFR0crMDBQqamp2rp1q9dMRUWFRo4cqWbNmik4OFh9+vTR3r17vWZKS0uVmZkpp9Mpp9OpzMxMHT58uM4HCAAAgCtfnaP12LFjuuWWW5SXl1fj/qlTp2ratGnKy8tTUVGRXC6XunXrpiNHjtgzWVlZWrp0qZYsWaK1a9fq6NGjSk9PV1VVlT2TkZGh4uJi5efnKz8/X8XFxcrMzLyAQwQAAMCVzreuL+jVq5d69epV4z7LsjRjxgyNGzdO999/vyRpwYIFioyM1OLFizVkyBB5PB699NJLevXVV9W1a1dJ0sKFCxUTE6N3331XPXr00LZt25Sfn6/CwkIlJiZKkubOnaukpCTt2LFDbdq0udDjBQAAwBXokl7TunPnTrndbnXv3t3eFhAQoJSUFK1fv16StHnzZp04ccJrJjo6Wu3atbNnCgoK5HQ67WCVpM6dO8vpdNozZ6qoqFBZWZnXAwAAAFeHSxqtbrdbkhQZGem1PTIy0t7ndrvl7++vpk2b1joTERFR7f0jIiLsmTPl5uba1786nU7FxMRc9PEAAADADJfl7gEOh8PruWVZ1bad6cyZmuZre5/s7Gx5PB77sWfPngtYOQAAAEx0SaPV5XJJUrWzoQcOHLDPvrpcLlVWVqq0tLTWmZKSkmrvf/DgwWpncU8LCAhQaGio1wMAAABXh0sarbGxsXK5XFq5cqW9rbKyUmvWrFFycrIkKSEhQX5+fl4z+/fv15YtW+yZpKQkeTwebdy40Z7ZsGGDPB6PPQMAAIAfjzrfPeDo0aP68ssv7ec7d+5UcXGxwsLC1LJlS2VlZSknJ0dxcXGKi4tTTk6OgoKClJGRIUlyOp0aOHCgnnjiCYWHhyssLEyjR49W+/bt7bsJxMfHq2fPnho0aJBmz54tSRo8eLDS09O5cwAAAMCPUJ2jddOmTbrrrrvs548//rgkqX///po/f77GjBmj8vJyDRs2TKWlpUpMTNSKFSsUEhJiv2b69Ony9fVV3759VV5errS0NM2fP18+Pj72zKJFizRq1Cj7LgN9+vQ5671hAQAAcHVzWJZlNfQiLoeysjI5nU55PJ6r5vrWa5/8Z0Mv4ZLa9Uzvhl4CfiSupp8dfm4AXE3q0muX5e4BAAAAwKVEtAIAAMB4db6mFQAAXP2upstqJC6tuRpwphUAAADGI1oBAABgPKIVAAAAxiNaAQAAYDyiFQAAAMYjWgEAAGA8ohUAAADGI1oBAABgPKIVAAAAxiNaAQAAYDyiFQAAAMYjWgEAAGA8ohUAAADGI1oBAABgPKIVAAAAxiNaAQAAYDyiFQAAAMYjWgEAAGA8ohUAAADGI1oBAABgPKIVAAAAxiNaAQAAYDyiFQAAAMYjWgEAAGA8ohUAAADGI1oBAABgPKIVAAAAxiNaAQAAYDyiFQAAAMYjWgEAAGA8ohUAAADGI1oBAABgPKIVAAAAxiNaAQAAYDyiFQAAAMYjWgEAAGA8ohUAAADGI1oBAABgPKIVAAAAxiNaAQAAYDyiFQAAAMYjWgEAAGA8ohUAAADGI1oBAABgPKIVAAAAxiNaAQAAYDyiFQAAAMYjWgEAAGA8ohUAAADGI1oBAABgPKIVAAAAxiNaAQAAYDzjo/XPf/6zYmNj1ahRIyUkJOiDDz5o6CUBAACgnhkdra+//rqysrI0btw4ffTRR+rSpYt69eqlr7/+uqGXBgAAgHpkdLROmzZNAwcO1KOPPqr4+HjNmDFDMTExmjVrVkMvDQAAAPXIt6EXcDaVlZXavHmznnzySa/t3bt31/r166vNV1RUqKKiwn7u8XgkSWVlZZd3ofXoVMV/G3oJl9TV9N8GZruafnb4uUF9uZp+biR+dkx1+r+LZVnnnDU2Wr/99ltVVVUpMjLSa3tkZKTcbne1+dzcXD399NPVtsfExFy2NeLiOGc09AqAKw8/N8CF4WfHbEeOHJHT6ax1xthoPc3hcHg9tyyr2jZJys7O1uOPP24/P3XqlL777juFh4fXOI+GVVZWppiYGO3Zs0ehoaENvRzgisDPDXBh+Nkxl2VZOnLkiKKjo885a2y0NmvWTD4+PtXOqh44cKDa2VdJCggIUEBAgNe2Jk2aXM4l4hIIDQ3lf0CAOuLnBrgw/OyY6VxnWE8z9hex/P39lZCQoJUrV3ptX7lypZKTkxtoVQAAAGgIxp5plaTHH39cmZmZ6tixo5KSkjRnzhx9/fXXGjp0aEMvDQAAAPXI6Gjt16+fDh06pEmTJmn//v1q166d3n77bbVq1aqhl4aLFBAQoAkTJlS7pAPA2fFzA1wYfnauDg7rfO4xAAAAADQgY69pBQAAAE4jWgEAAGA8ohUAAADGI1oBAABgPKIVAAAAxjP6llcA8GO2d+9ezZo1S+vXr5fb7ZbD4VBkZKSSk5M1dOhQxcTENPQSAaDecKYVDW7Pnj165JFHGnoZgFHWrl2r+Ph4LV26VLfccoseeugh/frXv9Ytt9yiZcuW6aabbtK6desaepnAFaekpESTJk1q6GXgAnCfVjS4jz/+WLfddpuqqqoaeimAMTp16qQ777xT06dPr3H/b3/7W61du1ZFRUX1vDLgysafOVcuLg/AZbd8+fJa93/11Vf1tBLgyrFlyxYtXLjwrPuHDBmiF198sR5XBFwZPvnkk1r379ixo55WgkuNaMVld99998nhcKi2k/oOh6MeVwSYLyoqSuvXr1ebNm1q3F9QUKCoqKh6XhVgvltvvfWsf+ac3s6fOVcmohWXXVRUlP70pz/pvvvuq3F/cXGxEhIS6ndRgOFGjx6toUOHavPmzerWrZsiIyPlcDjkdru1cuVK/eUvf9GMGTMaepmAccLDwzVlyhSlpaXVuH/r1q26995763lVuBSIVlx2CQkJ+vDDD88arec6Cwv8GA0bNkzh4eGaPn26Zs+ebV9/5+Pjo4SEBL3yyivq27dvA68SME9CQoL27dunVq1a1bj/8OHD/JlzhSJacdn9v//3/3Ts2LGz7r/++uv13nvv1eOKgCtDv3791K9fP504cULffvutJKlZs2by8/Nr4JUB5hoyZEitf+a0bNlS8+bNq8cV4VLh7gEAAOCqtm7dOnXs2FEBAQENvRRcBKIVAABc1UJDQ1VcXKzrrruuoZeCi8A/LgAAAK5qnJ+7OhCtAAAAMB7RCgAArmqzZ89WZGRkQy8DF4lrWgEAAGA8zrQCAADAeEQrAAAAjEe0AgAAwHhEKwAYYteuXXI4HCouLm7opQCAcYhWAAAAGI9oBQAAgPGIVgCoZ6dOndKUKVN0/fXXKyAgQC1bttQf/vCHanNVVVUaOHCgYmNjFRgYqDZt2mjmzJleM++//75uv/12BQcHq0mTJrrjjju0e/duSdLHH3+su+66SyEhIQoNDVVCQoI2bdpUL8cIAJeab0MvAAB+bLKzszV37lxNnz5dd955p/bv36/t27dXmzt16pRatGihN954Q82aNdP69es1ePBgRUVFqW/fvjp58qTuu+8+DRo0SK+99poqKyu1ceNGORwOSdKDDz6oDh06aNasWfLx8VFxcbH8/Pzq+3AB4JLgHxcAgHp05MgRNW/eXHl5eXr00Ue99u3atUuxsbH66KOPdOutt9b4+uHDh6ukpER//etf9d133yk8PFzvv/++UlJSqs2GhobqhRdeUP/+/S/HoQBAveLyAACoR9u2bVNFRYXS0tLOa/7FF19Ux44d1bx5czVu3Fhz587V119/LUkKCwvTgAED1KNHD917772aOXOm9u/fb7/28ccf16OPPqquXbvqmWee0X/+85/LckwAUB+IVgCoR4GBgec9+8Ybb+i3v/2tHnnkEa1YsULFxcV6+OGHVVlZac/MmzdPBQUFSk5O1uuvv64bbrhBhYWFkqSJEydq69at6t27t1avXq22bdtq6dKll/yYAKA+cHkAANSj48ePKywsTM8///w5Lw8YOXKkPvvsM61atcqe6dq1q7799tuz3ss1KSlJnTp10vPPP19t3wMPPKBjx45p+fLll/SYAKA+cKYVAOpRo0aNNHbsWI0ZM0avvPKK/vOf/6iwsFAvvfRStdnrr79emzZt0r/+9S99/vnneuqpp1RUVGTv37lzp7Kzs1VQUKDdu3drxYoV+vzzzxUfH6/y8nKNGDFC77//vnbv3q1169apqKhI8fHx9Xm4AHDJcPcAAKhnTz31lHx9fTV+/Hjt27dPUVFRGjp0aLW5oUOHqri4WP369ZPD4dADDzygYcOG6Z133pEkBQUFafv27VqwYIEOHTqkqKgojRgxQkOGDNHJkyd16NAhPfTQQyopKVGzZs10//336+mnn67vwwWAS4LLAwAAAGA8Lg8AAACA8YhWAAAAGI9oBQAAgPGIVgAAABiPaAUAAIDxiFYAAAAYj2gFAACA8YhWAAAAGI9oBQAAgPGIVgAAABiPaAUAAIDxiFYAAAAY7/8DkEIcaXqLyFAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "polarity_distribution.plot(kind='bar', figsize=(8, 6), legend=False, \n",
    "                           title=\"Nombre d'avis par classe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graphiquement, nous observons bien qu'il y a beaucoup plus d'avis positifs que d'avis neutres ou négatifs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous affichons les 10 premiers avis pour voir à quoi ressemble les données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ce n'est pas le premier roman à aborder les thèmes lourds de l'inceste et de l'enfance martyre, mais il le fait avec une audace et un brio incomparables qui rendent ce livre marquant dans une vie de lecteur. On y sent à quel point l'auteur n'a pas cherché à \"faire quelque chose\", on ne sent jamais l'intention, on sent juste l'urgence, incandescente, à raconter la vérité d'un homme maltraité par la vie au point de dire à la nuit «  tu ne me feras pas peur j'ai plus de noir que toi dans mon enfance ».\n",
      "------------------------\n",
      "Simple, alias Barnabé, est un jeune homme de 22 ans qui a l’âge mental d’un enfant de 3 ans. Kléber, son frère de 17 ans, entre en terminale au lycée, mais décide de s’occuper lui-même de son frère. Leur mère étant morte et leur père refusant de s’encombrer de sa progéniture afin de vivre pleinement sa nouvelle vie, Kléber refuse d’abandonner son frère à Malicroix, l’institution où il dépérissait. Se mettant tant bien que mal à la recherche d’un appartement pour vivre avec son frère, Kléber tombe sur un logement en colocation où d’autres étudiants vont vite découvrir que vivre avec Simple n’est pas toujours… aisé !\n",
      "------------------------\n",
      "Pour écrire La plus secrète mémoire des hommes, Mohamed Mbougar Sarr s'est inspiré du destin brisé de Yambo Ouologuem, premier écrivain africain à remporter le Prix Renaudot en 1968 avec Le devoir de violence, à 28 ans. Il a connu la gloire, puis l’opprobre, finissant sa vie reclus, honni par ses pairs.\n",
      "------------------------\n",
      "« La violence d'Aurélien est revenue. Par la fenêtre, peut-être bien. C'est une surprise qui te foudroie. Depuis l'épisode des miettes, ses mots te fauchent comme une gifle. T'écorchent et t'humilient. Sa main ne se lève pas, mais de sa bouche les torgnoles tombent de nouveau. Et c'est une claque au coeur, chaque fois. Tu tournes le thermostat de la douche à fond. Mais cela ne suffit pas. Ça fait des jours que tu as froid. Il y a en toi quelque chose de glacé que rien ne parvient à réchauffer. Et dans ta tête, la phrase assassine qui a tué tes pauvres rêves de paix et de petits bonheurs tranquilles n'en finit plus de tourner. « Ferme ta gueule une bonne fois pour toutes, connasse, si tu veux pas que je la réduise en miettes. » »\n",
      "------------------------\n",
      "Dans ce second album de La Guerre d’Alan, Emmanuel Guibert m’a fait suivre à nouveau les pas de cet homme, Alan Cope, jeune soldat étasunien de vingt ans qui vient de débarquer en France.\n",
      "------------------------\n",
      "Evocation des guerres de religion, Les serviteurs inutiles romancent la vie des Feuillades, une famille périgourdine, dans la seconde moitié du XVI siècle endeuillée par les massacres de la Saint Barthélémy (24 aout 1572).\n",
      "------------------------\n",
      "Voilà un roman au sujet atypique nous venant de la Chine communiste, où les nouveaux milliardaires donnent lieu à de nouveaux conflits de classe avec le monde des domestiques qu'ils ont à leur service.\n",
      "------------------------\n",
      "Trois livres composent ce grand livre. Chaque livre se divise en plusieurs parties complétées par ce que Mohamed Mbouga Sarr, l’auteur, appelle des biographèmes, le tout étant un formidable hommage à Yambo Ouologuem, écrivain malien (1940 – 2017), lauréat du Prix Renaudot en 1968 avec Le Devoir de violence. Premier romancier africain à recevoir une telle récompense, il fut accusé ensuite de plagiat, meurtrissure qu’il ne surmontera jamais vraiment.\n",
      "------------------------\n",
      "♫Il est temps de venir à bout\n",
      "------------------------\n",
      "« C'est incroyable comme l'espoir plane tout près du désespoir ».\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in list(data['reader_review'][0:10]):\n",
    "    print(i)\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que certains avis ne sont pas réellement des avis mais un résumé du livre ou une citation de celui-ci. Ces derniers devraient être classé dans la catégorie neutre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Séparation des données\n",
    "\n",
    "Nous séparons les données en deux jeux de données : un jeu d'entrainement et un jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement : 6430\n",
      "Taille de l'ensemble de test : 3215\n"
     ]
    }
   ],
   "source": [
    "# On mélange les lignes du DataFrame\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# On utilise la fonction train_test_split pour diviser le DataFrame\n",
    "train_df, test_df = train_test_split(data, train_size=2/3, random_state=42)\n",
    "\n",
    "# On affiche les informations sur les ensembles d'entraînement et de test\n",
    "print(\"Taille de l'ensemble d'entraînement :\", len(train_df))\n",
    "print(\"Taille de l'ensemble de test :\", len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prétraitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Lemmatisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatiser un texte implique de réduire chaque mot à sa forme de base ou à son \"lemme\".\n",
    "Cela implique la suppression des variations grammaticales (comme les temps verbaux, les genres, les nombres, etc.) pour regrouper les mots qui ont la même signification de base. \n",
    "\n",
    "La lemmatisation est souvent utilisée pour améliorer la précision de l'analyse en réduisant les variations de mots à leur forme canonique. Cela aide à regrouper les mots apparentés et à réduire la complexité lors de l'analyse textuelle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatisation(text):\n",
    "    text = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in text]\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On applique la lemmatisation sur les avis des livres des jeux de données d'aprentissage et de test. Le résultat de cette lemmatisation sera stocké dans une nouvelle colonne. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlemme\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreader_review\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(lemmatisation)\n",
      "File \u001b[1;32mc:\\Users\\clemc\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4521\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4525\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4528\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4628\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\u001b[38;5;28mself\u001b[39m, func, convert_dtype, args, kwargs)\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32mc:\\Users\\clemc\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\clemc\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmap_infer(\n\u001b[0;32m   1077\u001b[0m             values,\n\u001b[0;32m   1078\u001b[0m             f,\n\u001b[0;32m   1079\u001b[0m             convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype,\n\u001b[0;32m   1080\u001b[0m         )\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\clemc\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m, in \u001b[0;36mlemmatisation\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemmatisation\u001b[39m(text):\n\u001b[1;32m----> 2\u001b[0m     text \u001b[38;5;241m=\u001b[39m nlp(text)\n\u001b[0;32m      3\u001b[0m     lemmas \u001b[38;5;241m=\u001b[39m [token\u001b[38;5;241m.\u001b[39mlemma_ \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m text]\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(lemmas)\n",
      "File \u001b[1;32mc:\\Users\\clemc\\anaconda3\\Lib\\site-packages\\spacy\\language.py:1049\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1049\u001b[0m     doc \u001b[38;5;241m=\u001b[39m proc(doc, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcomponent_cfg\u001b[38;5;241m.\u001b[39mget(name, {}))  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\clemc\\anaconda3\\Lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\clemc\\anaconda3\\Lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:264\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.predict\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\clemc\\anaconda3\\Lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:285\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\clemc\\anaconda3\\Lib\\site-packages\\thinc\\model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[0;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\clemc\\anaconda3\\Lib\\site-packages\\spacy\\ml\\tb_framework.py:34\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model, X, is_train):\n\u001b[1;32m---> 34\u001b[0m     step_model \u001b[38;5;241m=\u001b[39m ParserStepModel(\n\u001b[0;32m     35\u001b[0m         X,\n\u001b[0;32m     36\u001b[0m         model\u001b[38;5;241m.\u001b[39mlayers,\n\u001b[0;32m     37\u001b[0m         unseen_classes\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munseen_classes\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     38\u001b[0m         train\u001b[38;5;241m=\u001b[39mis_train,\n\u001b[0;32m     39\u001b[0m         has_upper\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_upper\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     40\u001b[0m     )\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m step_model, step_model\u001b[38;5;241m.\u001b[39mfinish_steps\n",
      "File \u001b[1;32mc:\\Users\\clemc\\anaconda3\\Lib\\site-packages\\spacy\\ml\\parser_model.pyx:250\u001b[0m, in \u001b[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\clemc\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32mc:\\Users\\clemc\\anaconda3\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\clemc\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32mc:\\Users\\clemc\\anaconda3\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32mc:\\Users\\clemc\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32mc:\\Users\\clemc\\anaconda3\\Lib\\site-packages\\thinc\\layers\\with_array.py:42\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, Xseq, is_train)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m](Xseq, is_train)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _list_forward(model, Xseq, is_train))\n",
      "File \u001b[1;32mc:\\Users\\clemc\\anaconda3\\Lib\\site-packages\\thinc\\layers\\with_array.py:76\u001b[0m, in \u001b[0;36m_list_forward\u001b[1;34m(model, Xs, is_train)\u001b[0m\n\u001b[0;32m     74\u001b[0m pad \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpad\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     75\u001b[0m lengths \u001b[38;5;241m=\u001b[39m NUMPY_OPS\u001b[38;5;241m.\u001b[39masarray1i([\u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m Xs])\n\u001b[1;32m---> 76\u001b[0m Xf \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mflatten(Xs, pad\u001b[38;5;241m=\u001b[39mpad)\n\u001b[0;32m     77\u001b[0m Yf, get_dXf \u001b[38;5;241m=\u001b[39m layer(Xf, is_train)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(dYs: ListXd) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ListXd:\n",
      "File \u001b[1;32mc:\\Users\\clemc\\anaconda3\\Lib\\site-packages\\thinc\\backends\\ops.py:341\u001b[0m, in \u001b[0;36mOps.flatten\u001b[1;34m(self, X, dtype, pad, ndim_if_empty)\u001b[0m\n\u001b[0;32m    339\u001b[0m     padded\u001b[38;5;241m.\u001b[39mappend(xp\u001b[38;5;241m.\u001b[39mzeros((pad,) \u001b[38;5;241m+\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:], dtype\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[0;32m    340\u001b[0m     X \u001b[38;5;241m=\u001b[39m padded\n\u001b[1;32m--> 341\u001b[0m result \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mconcatenate(X)\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     result \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39masarray(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_df['lemme'] = train_df['reader_review'].apply(lemmatisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le 26èm opus de aventure de San antonio réunir avec son acolyte préférer , Bérurier et Pinaud ( qui en prennent pour son grade de ailleurs ) ne figurer pas dans le meilleur de le série . le enquête se dérouler à Paris en partir de Halles , en passer par un bureau de Poste , le commissariat et quelque hôtel . un classique de le époque dire on , un investigation sur quelque jour dans le capitale et notre commissaire qui ne hésit pas à se salir le main pour découvrir le vérité . quant aux femme .... lui ne apprécier pas ce tome !\n",
      "------------------------\n",
      "«    mais alors ! le père Noël exister -t il ?   » , pour - raton se demander à le lecture de ce guide qui donne envie de s’ offrir enfin à soi - même de cadeau utile ? pouvoir - être , mais ce qu’ il y avoir de certain , c’ être qu’ on y parler très peu de le mère Noël qui avoir perdre son châle .\n",
      "------------------------\n",
      "je retrouver avec beaucoup de joie l’ auteure , Marjane satrapi m’ avoir éblouir par son maturité dans Persépolis et je le retrouve tout aussi excellent dans Poulet à prune . on débarquer à Téhéran en 1958 , on retrouver le famille de l’ auteure dans ce opus mais pas de souci si vous n’ avoir pas lire Persépolis , c’ être un histoire inédit qu’ lui nous présente , toutefois je vous le conseil , il être magnifique .\n",
      "------------------------\n",
      "récit feuilletonnesque à souhait écrire par un duma jamais en manque de imagination . le aventure de Edmond Dantes être universel dans le mesure où lui pouvoir être délocaliser souher pour se inscrire dans ne importer quel pays . le auteur parl ici d vengeance et de droit à le justice . en se servir de son fortune , le protagoniste rétablit le ordre un chose et punir le scélérat en pointer leur turpitude . le personnage être bien sûr devenu de archétype au même titre que celui imaginer par Hugo . un classique !\n",
      "------------------------\n",
      "ce être un livre très agréable à lire . le auteur examin un foultitude de question concret , qui relever un mathématique simple , illustrer par un figure très clair . parmi le nombreux sujet aborder , je citer par exemple : le formation de embouteillage , le code informatique , le profil de piste de skateboard , le définition de jour de Pâques , le effet Magnus , le fort de Vauban , le forme de virage de tgv , le manière de paver , le extinction massif de espèce sur le terre , etc … Hervé Lehning expliquer bien et sans entrer dans le détail inutile . quelque « jeu » émailler le page . Bravo pour ce ouvrage !\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in list(train_df['lemme'][0:5]):\n",
    "    print(i)\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous faisons la même chose pour le jeu de données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['lemme'] = test_df['reader_review'].apply(lemmatisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "troisième aventure de Tori et son mage .\n",
      "------------------------\n",
      "et s’ il falloir choisir celui qui être sauver ?\n",
      "------------------------\n",
      "se attaquer à 667 page ( dense ) de ce biographie de Fouché pouvoir apparaître comme un challenge . mais le talent de historien de Emmanuel de Waresquiel avoir vite faire de donner le envie de parcourir ce ouvrage avec détermination !\n",
      "------------------------\n",
      "ce ouvrage plaire à petit comme à grand , à adepte de beal livre illustrer comme à sorcière et sorcier en herbe .\n",
      "------------------------\n",
      "livre fantastique remplir de émotion de début à le fin . le lecture de un chapitre me donner envie de connaître le suite . je avoir dévorer ce livre . par contre , quand le fin arriver , quel tristesse de laisser ce personnage . je avoir envier de continuer un petit bout de chemin avec lui .\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in list(test_df['lemme'])[0:5]:\n",
    "    print(i)\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous remarquons que la lemmatisation a bien fonctionné."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Racine des mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous remplaçons les mots par leur racine. Cela permet de réduire la complexité lors de l'analyse textuelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_text(text):\n",
    "    tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "    stemmer = FrenchStemmer('french')\n",
    "    stems = [stemmer.stem(token) for token in tokenizer.tokenize(text)]\n",
    "    return ' '.join(stems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la même manière, nous créons une nouvelle colonne qui contiendra le texte racinisé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['stems'] = train_df['reader_review'].apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le 26em opus des aventur de san antonio réun avec ses acolyt préfer , béruri et pinaud ( qui en prennent pour leur grad d'ailleur ) ne figur pas dans les meilleur de la ser . l'enquêt se déroul à paris en part des hall , en pass par des bureau de post , le commissariat et quelqu hôtel . un classiqu de l'époqu dir on , des investig sur quelqu jour dans la capital et notre commissair qui n'hésit pas à se sal les main pour découvr la vérit . quant aux femm ... elle n'appréci pas ce tom !\n",
      "------------------------\n",
      "« mais alor ! le per noël existera-t-il ? » , pour-raton se demand à la lectur de ce guid qui don envi de s ’ offrir enfin à soi-mêm des cadeau util ? peut-êtr , mais ce qu ’ il y a de certain , c ’ est qu ’ on y parl tres peu de la mer noël qui a perdu son châl .\n",
      "------------------------\n",
      "je retrouv avec beaucoup de joi l ’ auteur , marjan satrap m ’ avait éblou par sa matur dans persépol et je la retrouv tout auss excellent dans poulet aux prun . on débarqu à téhéran en 1958 , on retrouv la famill de l ’ auteur dans cet opus mais pas de souc si vous n ’ avez pas lu persépol , c ’ est une histoir inédit qu ’ elle nous présent , toutefois je vous le conseil , il est magnif .\n",
      "------------------------\n",
      "rec feuilletonnesqu à souh écrit par un dum jam en manqu d'imagin . les aventur d'edmond dant sont universel dans la mesur où elle peuvent être délocalis souh pour s'inscrir dans n'import quel pay . l'auteur parl ici d vengeanc et du droit à la justic . en se serv de sa fortun , le protagon rétabl l'ordr des chos et pun les scélérat en point leur turpitud . les personnag sont bien sûr devenus des archétyp au même titr que ceux imagin par hugo . un classiqu !\n",
      "------------------------\n",
      "c'est un livr tres agréabl à lir . l'auteur examin une foultitud de question concret , qui relèvent des mathémat simpl , illustr par des figur tres clair . parm les nombreux sujet abord , je cit par exempl : la format des embouteillag , les cod informat , le profil des pist de skateboard , la définit du jour de pâqu , l'effet magnus , les fort de vauban , la form de virag du tgv , les mani de pav , les extinct massiv des espec sur la terr , etc … herv lehning expliqu bien et san entrer dans les détail inutil . quelqu « jeux » émaillent les pag . bravo pour cet ouvrag !\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in list(train_df['stems'])[0:5]:\n",
    "    print(i)\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous faisons la même chose pour le jeu de données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['stems'] = test_df['reader_review'].apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "troisiem aventur de tor et ses mag .\n",
      "------------------------\n",
      "et s ’ il fall chois ceux qui seraient sauv ?\n",
      "------------------------\n",
      "s'attaqu aux 667 pag ( dens ) de cet biograph de fouch peut apparaîtr comm un challeng . mais le talent d'historien d'emmanuel de waresquiel a vit fait de don l'env de parcour cet ouvrag avec détermin !\n",
      "------------------------\n",
      "cet ouvrag plair aux petit comm aux grand , aux adept de beau livr illustr comm aux sorci et sorci en herb .\n",
      "------------------------\n",
      "livr fantast rempl d'émot du début à la fin . la lectur d'un chapitr me don envi de connaîtr la suit . j'ai dévor ce livr . par contr , quand la fin arriv , quel tristess de laiss ces personnag . j'av envi de continu un pet bout de chemin avec eux .\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in list(test_df['stems'][0:5]):\n",
    "    print(i)\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous remarquons bien que la racinisation a fonctionné. Nous remarquons également la différence avec la lemmatisation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Etiquetage morphosyntaxique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cela va nous permettre d'attribuer des étiquettes grammaticales à chaque mot dans une phrase, indiquant ainsi leur catégorie grammaticale ou leur rôle dans la phrase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_words_with_pos_tag(text):\n",
    "    text = nlp(text)\n",
    "    return ' '.join([token.pos_ for token in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['pos'] = train_df['reader_review'].apply(replace_words_with_pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DET ADJ NOUN ADP NOUN ADP PROPN NOUN VERB ADP DET NOUN VERB PUNCT PROPN CCONJ PROPN PUNCT PRON PRON NOUN ADP DET NOUN ADP ADV PUNCT ADV VERB ADV ADP DET NOUN ADP DET NOUN PUNCT DET NOUN PRON VERB ADP PROPN ADP VERB ADP PROPN PUNCT ADP VERB ADP DET NOUN ADP PROPN PUNCT DET NOUN CCONJ DET NOUN PUNCT DET NOUN ADP DET NOUN VERB PRON PUNCT DET NOUN ADP DET NOUN ADP DET NOUN CCONJ DET NOUN PRON ADV ADJ ADV ADP PRON VERB DET NOUN ADP VERB DET NOUN PUNCT ADV DET NOUN PUNCT PRON ADV VERB ADV DET NOUN PUNCT\n",
      "------------------------\n",
      "ADJ SPACE CCONJ ADV PUNCT DET NOUN PROPN AUX PRON PRON PUNCT SPACE PUNCT PUNCT ADP PROPN ADJ PRON VERB ADP DET NOUN ADP DET NOUN PRON VERB NOUN ADP PROPN VERB ADV ADP PRON ADV ADV ADP NOUN ADJ PUNCT ADV ADV ADV PUNCT CCONJ PRON PROPN PRON PRON VERB ADP ADJ PUNCT NOUN AUX SCONJ PRON PRON VERB ADV ADV ADP DET NOUN PROPN PRON AUX VERB DET NOUN PUNCT\n",
      "------------------------\n",
      "PRON VERB ADP ADV ADP VERB ADJ VERB PUNCT PROPN DET NOUN AUX VERB ADP DET NOUN ADP PROPN CCONJ PRON DET NOUN ADV ADV ADV ADP PROPN ADP NOUN PUNCT PRON VERB ADP PROPN ADP NUM PUNCT PRON VERB DET NOUN ADP NOUN VERB ADP DET NOUN CCONJ ADV ADP ADJ SCONJ PRON VERB VERB ADV PROPN PROPN PUNCT NOUN AUX DET NOUN VERB SCONJ PRON PRON VERB PUNCT ADV PRON PRON DET NOUN PUNCT PRON AUX ADJ PUNCT\n",
      "------------------------\n",
      "NOUN ADJ ADP NOUN VERB ADP DET NOUN ADV ADP NOUN ADP NOUN PUNCT DET NOUN ADP PROPN PROPN AUX ADJ ADP DET NOUN PRON PRON VERB AUX VERB VERB ADP PRON VERB ADP ADV VERB DET NOUN PUNCT DET NOUN ADJ ADV ADP NOUN CCONJ ADP NOUN ADP DET NOUN PUNCT ADP PRON VERB ADP DET NOUN PUNCT DET NOUN ADJ DET NOUN DET NOUN CCONJ VERB DET NOUN ADP VERB DET NOUN PUNCT DET NOUN AUX ADV ADJ NOUN ADP NOUN ADP ADJ NOUN SCONJ PRON VERB ADP PROPN PUNCT DET NOUN PUNCT\n",
      "------------------------\n",
      "PRON AUX DET NOUN ADV ADJ ADP VERB PUNCT DET NOUN ADJ DET NOUN ADP NOUN ADJ PUNCT PRON VERB DET NOUN ADJ PUNCT VERB ADP DET NOUN ADV ADJ PUNCT ADP DET ADJ NOUN VERB PUNCT PRON VERB ADP NOUN PUNCT DET NOUN ADP NOUN PUNCT DET NOUN ADJ PUNCT DET NOUN ADP NOUN ADP NOUN PUNCT DET NOUN ADP NOUN ADP PROPN PUNCT DET NOUN PROPN PUNCT DET NOUN ADP PROPN PUNCT DET NOUN ADP NOUN ADP NOUN PUNCT DET NOUN ADP VERB PUNCT DET NOUN ADJ ADP NOUN ADP DET NOUN PUNCT PROPN PUNCT PROPN PROPN VERB ADV CCONJ ADP VERB ADP DET NOUN NOUN PUNCT DET NOUN NOUN PUNCT VERB DET NOUN PUNCT PROPN ADP DET NOUN PUNCT\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in list(train_df['pos'][0:5]):\n",
    "    print(i)\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous faisons la même chose pour le jeu de données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pos'] = test_df['reader_review'].apply(replace_words_with_pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADJ NOUN ADP PROPN CCONJ DET NOUN PUNCT\n",
      "------------------------\n",
      "CCONJ PRON PRON VERB NOUN PRON PRON AUX VERB PUNCT\n",
      "------------------------\n",
      "PRON VERB ADP NUM NOUN PUNCT ADJ PUNCT ADP DET NOUN ADP PROPN VERB VERB ADP DET NOUN PUNCT CCONJ DET NOUN ADP NOUN ADP PROPN ADP PROPN AUX ADV VERB ADP VERB DET NOUN ADP VERB DET NOUN ADP NOUN PUNCT\n",
      "------------------------\n",
      "DET NOUN VERB ADP ADJ ADP ADP NOUN PUNCT ADP NOUN ADP ADJ NOUN VERB ADP ADP NOUN CCONJ ADJ ADP NOUN PUNCT\n",
      "------------------------\n",
      "NOUN ADJ VERB ADP NOUN ADP NOUN ADP DET NOUN PUNCT DET NOUN ADP DET NOUN PRON VERB NOUN ADP VERB DET NOUN PUNCT PRON AUX VERB DET NOUN PUNCT ADP NOUN PUNCT SCONJ DET NOUN VERB PUNCT DET NOUN ADP VERB DET NOUN PUNCT PRON VERB VERB ADP VERB DET ADJ NOUN ADP NOUN ADP PRON PUNCT\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in list(test_df['pos'][0:5]):\n",
    "    print(i)\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Entités nommées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les entités nommées sont des éléments spécifiques dans un texte qui font référence à des personnes, des lieux, des organisations, des dates, des quantités, etc. L'identification et l'étiquetage des entités nommées sont essentiels dans le traitement automatique du langage naturel pour pouvoir extraire des informations clés d'un texte. \n",
    "\n",
    "Par exemple, dans un article de presse, repérer les noms des personnes, des lieux ou des organisations est crucial pour comprendre le contenu et ses acteurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner(text):\n",
    "    text = nlp(text)\n",
    "    new_text = []\n",
    "    for token in text:\n",
    "        if token.ent_iob_ == \"O\":\n",
    "            new_text.append(token.text)\n",
    "        elif token.ent_iob_ == \"B\":\n",
    "            new_text.append(token.ent_type_)\n",
    "        # Si l'entité comprend plusieurs mot on ne répète pas l'étiquette\n",
    "        else:\n",
    "            continue\n",
    "    return ' '.join(new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour expliquer cette fonction, nous prenons l'exemple avec la phrase suivante :\n",
    "\"Elle vit à Paris et travaille chez Google. Elle a rencontré John Doe à New York.\"\n",
    "\n",
    "La fontion pour chaque mot donne le résultat suivant :\n",
    "\n",
    "- \"Elle\" : \"O\" (Outside), car ce mot ne fait pas partie d'une entité nommée.\n",
    "\n",
    "- \"vit\" : \"O\" (Outside), pas une entité nommée.\n",
    "\n",
    "- \"à\" : \"O\" (Outside), pas une entité nommée.\n",
    "\n",
    "- \"Paris\" :\"B\" (Beginning) et ent_type_ = \"LIEU\" , car c'est le début d'une entité nommée de type \"LIEU\".\n",
    "\n",
    "- \"et\" : \"O\" (Outside), pas une entité nommée.\n",
    "\n",
    "- \"travaille\" : \"O\" (Outside), pas une entité nommée.\n",
    "\n",
    "- \"chez\" : \"O\" (Outside), pas une entité nommée.\n",
    "\n",
    "- \"Google\" : \"B\" (Beginning) et ent_type_ = \"ORGANISATION\", car c'est le début d'une entité nommée de type \"ORGANISATION\".\n",
    "\n",
    "- \".\" : \"O\" (Outside), pas une entité nommée.\n",
    "\n",
    "- \"Elle\" : \"O\" (Outside), pas une entité nommée.\n",
    "\n",
    "- \"a\" : \"O\" (Outside), pas une entité nommée.\n",
    "\n",
    "- \"rencontré\" : \"O\" (Outside), pas une entité nommée.\n",
    "\n",
    "- \"John\" : \"B\" (Beginning) et ent_type_ = \"PERSONNE\", car c'est le début d'une entité nommée de type \"PERSONNE\".\n",
    "\n",
    "- \"Doe\" : \"I\" (Inside) et ent_type_ = \"PERSONNE\", car c'est la suite d'une entité nommée de type \"PERSONNE\".\n",
    "\n",
    "- \"à\" : \"O\" (Outside), pas une entité nommée.\n",
    "\n",
    "- \"New\" : \"B\" (Beginning) et ent_type_ = \"LIEU\", car c'est le début d'une entité nommée de type \"LIEU\".\n",
    "\n",
    "- \"York\" : \"I\" (Inside) et ent_type_ = \"LIEU\", car c'est la suite d'une entité nommée de type \"LIEU\".\n",
    "\n",
    "- \".\" : \"O\" (Outside), pas une entité nommée.\n",
    "\n",
    "\n",
    "Les entités de type I ne sont pas affichées.\n",
    "Pour les mots de type B, ils seront remplacées par le type de l'entité nommée. Par exemple, \"Paris\" sera remplacé par \"LIEU\".\n",
    "\n",
    "On aura donc la phrase suivante :\n",
    "\n",
    "\"Elle vit à LIEU et travaille chez ORGANISATION. Elle a rencontré PERSONNE à LIEU.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous appliquons cette fonction sur les jeux de données d'apprentissage et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['entites_nommees'] = train_df['reader_review'].apply(ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le 26ème opus des aventures de San Antonio réuni avec ses acolytes préférés , PER et PER ( qui en prennent pour leur grade d' ailleurs ) ne figure pas dans les meilleurs de la série . L' enquête se déroule à LOC en partant des LOC , en passant par des bureaux ORG , le commissariat et quelques hôtels . Un classique de l' époque dirait on , des investigations sur quelques jours dans la capitale et notre commissaire qui n' hésite pas à se salir les mains pour découvrir la vérité . Quant aux femmes .... elle n' apprécieront pas ce tome !\n",
      "------------------------\n",
      "«    Mais alors ! Le père MISC existera -t -il ?   » , pour - raton se demander à la lecture de ce guide qui donne envie de PER offrir enfin à soi - même des cadeaux utiles ? Peut - être , mais ce qu’ il y a de certain , MISC est LOC on y parle très peu de la mère MISC qui a perdu son châle .\n",
      "------------------------\n",
      "Je retrouve avec beaucoup de joie l’ auteure , MISC PER avait ébloui par sa maturité dans LOC et je la retrouve tout aussi excellent dans LOC aux prunes . On débarque à LOC en 1958 , on retrouve la famille de LOC auteure dans cet opus mais pas de soucis si vous PER avez pas lu LOC , MISC est une histoire inédite qu’ elle nous présente , toutefois je vous le conseil , il est magnifique .\n",
      "------------------------\n",
      "Récit feuilletonnesque à souhait écrit par un PER jamais en manque d' imagination . Les aventures d' PER sont universelles dans la mesure où elles peuvent être délocalisées souhait pour s' inscrire dans n' importe quel pays . L' auteur parle ici d vengeance et du droit à la justice . En se servant de sa fortune , le protagoniste rétablit l' ordre des choses et punit les scélérats en pointant leurs turpitudes . Les personnages sont bien sûr devenus des archétypes au même titre que ceux imaginés par PER . Un classique !\n",
      "------------------------\n",
      "C' est un livre très agréable à lire . L' auteur examine une foultitude de questions concrètes , qui relèvent des mathématiques simples , illustrées par des figures très claires . Parmi les nombreux sujets abordés , je citerai par exemple : la formation des embouteillages , les codes informatiques , le profil des pistes de skateboard , la définition du jour de MISC , l' effet PER , les forts de PER , la forme de virages du MISC , les manières de paver , les extinctions massives des espèces sur LOC , etc … PER explique bien et sans entrer dans les détails inutiles . Quelques « jeux » émaillent les pages . PER pour cet ouvrage !\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in list(train_df['entites_nommees'][0:5]):\n",
    "    print(i)\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['entites_nommees'] = test_df['reader_review'].apply(ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Troisième aventure de LOC et ses mages .\n",
      "------------------------\n",
      "Et LOC il fallait choisir ceux qui seraient sauvés ?\n",
      "------------------------\n",
      "S' attaquer aux 667 pages ( denses ) de cette biographie de PER peut apparaître comme un challenge . Mais le talent d' historien d' PER a vite fait de donner l' envie de parcourir cet ouvrage avec détermination !\n",
      "------------------------\n",
      "Cet ouvrage plaira aux petits comme aux grands , aux adeptes de beaux livres illustrés comme aux sorcières et sorciers en herbe .\n",
      "------------------------\n",
      "livre fantastique rempli d' émotions du début à la fin . la lecture d' un chapitre me donnait envie de connaître la suite . j' ai dévoré ce livre . par contre , quand la fin arrive , quelle tristesse de laisser ces personnages . j' avais envie de continuer un petit bout de chemin avec eux .\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in list(test_df['entites_nommees'][0:5]):\n",
    "    print(i)\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Traitement des URLS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous remplaçons les URL par un mot fictif. En effet, les URL peuvent poser problème dans l'apprentissage du modèle. C'est pourquoi nous les remplaçons par un mot unique choisi au préalable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remplacer_url(text, url_replacement='urlexpr'):\n",
    "    text = re.sub(r'https?:\\S+', url_replacement, text) # http://t.co/eFKkE9W0GI\n",
    "    text = re.sub(r'\\bwww\\.\\S+', url_replacement, text) # www.example.com\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['sans_url'] = train_df['reader_review'].apply(remplacer_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le 26ème opus des aventures de San Antonio réuni avec ses acolytes préférés, Bérurier et Pinaud (qui en prennent pour leur grade d'ailleurs) ne figure pas dans les meilleurs de la série. L'enquête se déroule à Paris en partant des Halles, en passant par des bureaux de Poste, le commissariat et quelques hôtels. Un classique de l'époque dirait on, des investigations sur quelques jours dans la capitale et notre commissaire qui n'hésite pas à se salir les mains pour découvrir la vérité. Quant aux femmes.... elle n'apprécieront pas ce tome !\n",
      "------------------------\n",
      "«  Mais alors ! Le père Noël existera-t-il ? », pour-raton se demander à la lecture de ce guide qui donne envie de s’offrir enfin à soi-même des cadeaux utiles ? Peut-être, mais ce qu’il y a de certain, c’est qu’on y parle très peu de la mère Noël qui a perdu son châle.\n",
      "------------------------\n",
      "Je retrouve avec beaucoup de joie l’auteure, Marjane Satrapi m’avait ébloui par sa maturité dans Persépolis et je la retrouve tout aussi excellent dans Poulet aux prunes. On débarque à Téhéran en 1958, on retrouve la famille de l’auteure dans cet opus mais pas de soucis si vous n’avez pas lu Persépolis, c’est une histoire inédite qu’elle nous présente, toutefois je vous le conseil, il est magnifique.\n",
      "------------------------\n",
      "Récit feuilletonnesque à souhait écrit par un Dumas jamais en manque d'imagination. Les aventures d'Edmond Dantes sont universelles dans la mesure où elles peuvent être délocalisées souhait pour s'inscrire dans n'importe quel pays. L'auteur parle ici d vengeance et du droit à la justice. En se servant de sa fortune, le protagoniste rétablit l'ordre des choses et punit les scélérats en pointant leurs turpitudes. Les personnages sont bien sûr devenus des archétypes au même titre que ceux imaginés par Hugo. Un classique !\n",
      "------------------------\n",
      "C'est un livre très agréable à lire. L'auteur examine une foultitude de questions concrètes, qui relèvent des mathématiques simples, illustrées par des figures très claires. Parmi les nombreux sujets abordés, je citerai par exemple: la formation des embouteillages, les codes informatiques, le profil des pistes de skateboard, la définition du jour de Pâques, l'effet Magnus, les forts de Vauban, la forme de virages du TGV, les manières de paver, les extinctions massives des espèces sur la Terre, etc… Hervé Lehning explique bien et sans entrer dans les détails inutiles. Quelques « jeux » émaillent les pages. Bravo pour cet ouvrage !\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in list(train_df[\"sans_url\"][0:5]):\n",
    "    print(i)\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous faisons la même chose pour le jeu de données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['sans_url'] = test_df['reader_review'].apply(remplacer_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1287                                       Insta: urlexpr\n",
       "604     Si ce roman promettait d'être ingénieux et ori...\n",
       "Name: sans_url, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultats = test_df[test_df['sans_url'].str.contains('urlexpr')]\n",
    "resultats['sans_url']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voyons bien que les liens sont été remplacés par 'urlexp'.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Suppression de certains mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La suppression de certains mots comme les \"mots vides\", c'est-à-dire les mots qui n'apportent pas d'information pour la classification, permettent de se focaliser sur les mots les plus importants. Par exemple, les mots \"et\", \"car\", \"le\", \"la\"... n'apportent pas d'information. \n",
    "De plus, les modèles d'analyse de sentiments peuvent être sensibles à la dimensionnalité élevée des données. \n",
    "\n",
    "En réduisant le vocabulaire, on réduit le nombre de mots que le modèle doit prendre en compte, ce qui peut améliorer l'efficacité de l'apprentissage et la vitesse d'entraînement.\n",
    "Certains mots peuvent apparaître rarement ou être spécifiques à des documents particuliers, ce qui peut introduire du bruit dans le modèle. \n",
    "Par ailleurs, en se concentrant sur les termes les plus fréquents et les plus informatifs, le modèle peut se généraliser plus efficacement à de nouveaux textes. Cela peut également contribuer à éviter le surajustement aux données d'entraînement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle', 'en', 'et', 'eux', 'il', 'ils', 'je', 'la', 'le', 'les', 'leur', 'lui', 'ma', 'mais', 'me', 'même', 'mes', 'moi', 'mon', 'ne', 'nos', 'notre', 'nous', 'on', 'ou', 'par', 'pas', 'pour', 'qu', 'que', 'qui', 'sa', 'se', 'ses', 'son', 'sur', 'ta', 'te', 'tes', 'toi', 'ton', 'tu', 'un', 'une', 'vos', 'votre', 'vous', 'c', 'd', 'j', 'l', 'à', 'm', 'n', 's', 't', 'y', 'été', 'étée', 'étées', 'étés', 'étant', 'étante', 'étants', 'étantes', 'suis', 'es', 'est', 'sommes', 'êtes', 'sont', 'serai', 'seras', 'sera', 'serons', 'serez', 'seront', 'serais', 'serait', 'serions', 'seriez', 'seraient', 'étais', 'était', 'étions', 'étiez', 'étaient', 'fus', 'fut', 'fûmes', 'fûtes', 'furent', 'sois', 'soit', 'soyons', 'soyez', 'soient', 'fusse', 'fusses', 'fût', 'fussions', 'fussiez', 'fussent', 'ayant', 'ayante', 'ayantes', 'ayants', 'eu', 'eue', 'eues', 'eus', 'ai', 'as', 'avons', 'avez', 'ont', 'aurai', 'auras', 'aura', 'aurons', 'aurez', 'auront', 'aurais', 'aurait', 'aurions', 'auriez', 'auraient', 'avais', 'avait', 'avions', 'aviez', 'avaient', 'eut', 'eûmes', 'eûtes', 'eurent', 'aie', 'aies', 'ait', 'ayons', 'ayez', 'aient', 'eusse', 'eusses', 'eût', 'eussions', 'eussiez', 'eussent']\n"
     ]
    }
   ],
   "source": [
    "sw = nltk.corpus.stopwords.words('french')\n",
    "print(sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous appliquerons ce corpus de mots vides à nos jeux de données d'apprentissage et de test dans la suite de notre étude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calcul des valeurs des descripteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Séparation du jeu de données d'entrainement en 2 jeux de données\n",
    "\n",
    "Nous séparons le jeu de données d'entrainement en 2 jeux de données : un jeu de données d'entrainement et un jeu de données de validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_df['reader_review'],\n",
    "                                                      train_df['label'],\n",
    "                                                      train_size=0.75,\n",
    "                                                      random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le jeu de données tests, on met la variable label dans un objet \"y_test\" et la colonne \"reader_review\" dans un objet \"X_test\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = test_df['reader_review'], test_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Numérique discret : décompte d'occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction CountVectorizer permet de compter le nombre d'occurences de chaque mot dans chaque avis. Elle transforme une liste de textes en une représentation numérique utilisable pour des algorithmes d'apprentissage automatique.\n",
    "\n",
    "Le processus de fit consiste à analyser le texte pour déterminer les mots uniques présents dans X_train et à créer une représentation vectorielle de ces mots. Chaque texte sera représenté comme un vecteur où chaque élément correspond à la fréquence d'apparition de chaque mot du vocabulaire dans ce texte.\n",
    "\n",
    "Ainsi, cela créé un objet \"CountVectorizer\" qui contient le vocabulaire de tous les mots de tous les avis.\\ Cet objet est appelé \"vect_count\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_count = CountVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche les 50 premiers noms des mots utilisés pour créer la représentation vectorielle des textes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['000', '02', '03', '08', '10', '100', '1000', '1078', '109', '11',\n",
       "       '112', '115', '12', '1200', '121', '125', '12ans', '12heures',\n",
       "       '13', '130', '130kg', '130p', '14', '140', '141', '1415', '1425',\n",
       "       '144', '14ans', '15', '150', '1518', '153', '15jours', '16', '160',\n",
       "       '1600', '1604', '1613', '1615', '164', '165', '1664', '1665',\n",
       "       '1691', '16ème', '17', '173', '1750', '1756'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_count.get_feature_names_out()[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche les 50 derniers noms des mots utilisés pour créer la représentation vectorielle des textes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['évoquée', 'évoquées', 'évoqués', 'évènement', 'évènementielle',\n",
       "       'évènements', 'événement', 'événements', 'êkho', 'êtes', 'être',\n",
       "       'êtres', 'île', 'îles', 'ïnes', 'ôshi', 'ôte', 'örn', 'œdipe',\n",
       "       'œdipienne', 'œil', 'œils', 'œuf', 'œufs', 'œuvre', 'œuvrent',\n",
       "       'œuvres', 'œuvré', 'достоевский', 'михайлович', 'фёдор', '日光流年',\n",
       "       '阎连科', '𝐻𝑒𝑎𝑟𝑡𝑠', '𝐽𝑒', '𝑁𝑜𝑒', '𝑇𝑎𝑖𝑛𝑡𝑒𝑑', '𝑎𝑖𝑚𝑒𝑟', '𝑓𝑒𝑟𝑎𝑖𝑠', '𝑡𝑒',\n",
       "       '𝗟𝗮', '𝗰𝗵𝗼𝘀𝗲', '𝗱𝗶𝘀𝗽𝗼𝘀𝗲𝘀', '𝗲𝗻', '𝗲𝘁', '𝗽𝗿𝗼𝗽𝗼𝘀𝗲', '𝗾𝘂𝗲𝗹𝗾𝘂𝗲', '𝘁𝗲',\n",
       "       '𝘁𝘂', '𝘃𝗶𝗲'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_count.get_feature_names_out()[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23492"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect_count.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi, nous créons une représentation vectorielle des données d'entraînement en se basant sur le vocabulaire établi précédemment. \n",
    "\n",
    "Donc, cette opération convertit les données textuelles en une matrice numérique où chaque ligne correspond à un texte et chaque colonne correspond à la fréquence d'un mot spécifique dans ce texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4822x23492 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 192491 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized_count = vect_count.transform(X_train)\n",
    "X_train_vectorized_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train_count est une matrice de taille (n_train=4822, n_features=23492) où n_train est le nombre de textes dans le jeu de données d'entraînement et n_features est le nombre de mots dans le vocabulaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous faisons la même chose pour le jeu de données de validation et de test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_vectorized_count = vect_count.transform(X_valid)\n",
    "X_test_vectorized_count = vect_count.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous créons un autre objet CountVectorizer mais cette fois-ci, nous posons certaines conditions : le mot doit apparaitre au moins 5 fois dans les documents pour être inclus dans le vocabulaie. De plus, les mots seront des unigrammes et des bigrammes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_count_bigrams = CountVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)\n",
    "X_train_vectorized_count_bigrams = vect_count_bigrams.transform(X_train)\n",
    "X_valid_vectorized_count_bigrams = vect_count_bigrams.transform(X_valid)\n",
    "X_test_vectorized_count_bigrams = vect_count_bigrams.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10483"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect_count_bigrams.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nombre de mots dans le vocabulaire a diminué du fait des conditions ajoutées dans le CountVectorizer. Il est passé d'environ 23 000 à environ 10 000. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Numérique continu : TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons décidé de créer 2 objets tfidfVectorizer : un avec les stopwords et un sans les stopwords. En effet, les mots entrés dans les stopwords peuvent être importants pour interpréter la polarité d'un avis.\\\n",
    "\n",
    "Par ailleurs, nous ajoutons dans notre représentation numérique les **bi-grammes**. En effet, ces derniers peuvent être importants pour interpréter la polarité d'un avis. Par exemple, \"pas bien\" est un bi-gramme qui donne une polarité négative alors que l'analyse du mot \"bien\" seul donnerait une polarité positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Avec stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_tfidf_sw = TfidfVectorizer(min_df=5, stop_words=sw, ngram_range=(1,2)).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23492, 5507)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect_count.get_feature_names_out()), len(vect_tfidf_sw.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le vocabulaire (numérique discret) il y a 23492 mots.\n",
    "\n",
    "Pour le vocabulaire (numérique continu) il y a 5507 mots.\n",
    "\n",
    "Pour rappel, nous avons supprimés les \"stops words\" du vocabulaire.\n",
    "\n",
    "Nous décidons de carder le dictionnaire de vocabulaire numérique continu à 5507 mots, car cela permet de réduire la dimensionnalité des données (nombre de vocabulaire à apprendre) et donc de réduire le temps de calcul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized_tfidf_sw = vect_tfidf_sw.transform(X_train)\n",
    "X_valid_vectorized_tfidf_sw = vect_tfidf_sw.transform(X_valid)\n",
    "X_test_vectorized_tfidf_sw = vect_tfidf_sw.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Sans stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_tfidf = TfidfVectorizer(min_df=5,ngram_range=(1,2)).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23492, 10483)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect_count.get_feature_names_out()), len(vect_tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Même conclusion ici, nous décidons de garder le dictionnaire de vocabulaire numérique continu à 19 483 mots. Ici, il y a plus de mots à apprendre car nous avons gardé les \"stops words\" et ajouté les bigrammes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized_tfidf = vect_tfidf.transform(X_train)\n",
    "X_valid_vectorized_tfidf = vect_tfidf.transform(X_valid)\n",
    "X_test_vectorized_tfidf = vect_tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Classification sans les stopwords "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant tester différents modèles et regarder leur accuracy afin de voir lequel d'entre eux est le plus performant et classifierait au mieux nos avis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Modèles de référence faibles (*weak baselines*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. Choix aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_prop_class = DummyClassifier(strategy='stratified').fit(X_train_vectorized_tfidf,\n",
    "                                                               y_train)\n",
    "predictions_valid = random_prop_class.predict(X_valid_vectorized_tfidf)\n",
    "conf_mat = confusion_matrix(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5  31  83]\n",
      " [ 20  94 228]\n",
      " [116 237 794]]\n"
     ]
    }
   ],
   "source": [
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5553482587064676"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'accuracy de ce premier modèle est de 55.53% ce qui signifie qu'il classe correctement un peu plus de la moitié de nos avis. Cela reste une performance moyenne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, -1,  1, ..., -1,  1,  1])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_uniform = DummyClassifier(strategy='uniform').fit(X_train_vectorized_tfidf,\n",
    "                                                         y_train)\n",
    "predictions_valid = random_uniform.predict(X_valid_vectorized_tfidf)\n",
    "predictions_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 42  41  36]\n",
      " [114 106 122]\n",
      " [382 379 386]]\n"
     ]
    }
   ],
   "source": [
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.332089552238806"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.08      0.35      0.13       119\n",
      "           0       0.20      0.31      0.24       342\n",
      "           1       0.71      0.34      0.46      1147\n",
      "\n",
      "    accuracy                           0.33      1608\n",
      "   macro avg       0.33      0.33      0.28      1608\n",
      "weighted avg       0.55      0.33      0.39      1608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La performance du modèle de classification est relativement faible. Il a du mal à bien classer les instances, comme en témoignent les faibles valeurs de précision, rappel et F1-score. L'exactitude est également basse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2. Prédiction constante de la classe majoritaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_reviews</th>\n",
       "      <th>pourcentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6658</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2129</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>858</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nb_reviews  pourcentage\n",
       "class                         \n",
       " 1           6658         0.69\n",
       " 0           2129         0.22\n",
       "-1            858         0.09"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarity_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons vérifier notre réponse : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maj = DummyClassifier(strategy='most_frequent').fit(X_train_vectorized_tfidf, y_train)\n",
    "predictions_valid = maj.predict(X_valid_vectorized_tfidf)\n",
    "predictions_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maj_class = (polarity_distribution.index[polarity_distribution.pourcentage ==\n",
    "                                      np.amax(polarity_distribution.pourcentage)][0])\n",
    "maj_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous observons bien que la classe majoritaire est 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(predictions_valid == maj_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7133084577114428"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maj.score(X_valid_vectorized_tfidf, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons environ 69% d'avis classés positifs. Cela reste donc normal que le score soit aux alentours de 71%, ce qui est proche de ce premier pourcentage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00       119\n",
      "           0       0.00      0.00      0.00       342\n",
      "           1       0.71      1.00      0.83      1147\n",
      "\n",
      "    accuracy                           0.71      1608\n",
      "   macro avg       0.24      0.33      0.28      1608\n",
      "weighted avg       0.51      0.71      0.59      1608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion modèles de référence faibles\n",
    "Ici, l'accuray du modèle faible n'est vraiment pas très bonne. Celle concernant la prédiction constante de la classe majoritaire est bonne mais c'est seulement car nous avons beaucoup d'avis positifs dans la base de données. Sinon, si le nombre d'avis dans chaque classe était plus homogène, l'accuracy aurait été bien inférieure. \n",
    "\n",
    "Nous allons donc continuer à tester d'autres modèles pour évaluer la performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Classifieur bayésien naïf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nb = MultinomialNB().fit(X_train_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_nb.predict(X_valid_vectorized_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7139303482587065"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle prédit correctement 71.39% des avis du jeu de données de validation.\n",
    "\n",
    "On affiche la matrice de confusion pour le jeu de données de validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.01      0.02       119\n",
      "           0       0.00      0.00      0.00       342\n",
      "           1       0.71      1.00      0.83      1147\n",
      "\n",
      "    accuracy                           0.71      1608\n",
      "   macro avg       0.57      0.34      0.28      1608\n",
      "weighted avg       0.58      0.71      0.60      1608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle a une précision élevée pour la classe 1 (71%), mais des performances très faibles pour les classes -1 et 0. Le rappel est particulièrement bas pour la classe -1. L'exactitude globale est de 71%, mais cela est largement dû à la prédominance de la classe 1. Le modèle peut être biaisé et nécessite une amélioration, en particulier pour mieux capturer les classes minoritaires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Régression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1. Premier modèle de régression logistique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression(multi_class='multinomial', solver='lbfgs',\n",
    "                              max_iter=200).fit(X_train_vectorized_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_valid = model_lr.predict(X_valid_vectorized_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6716417910447762"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre modèle de régression logistique prédit correctement 67.16% des avis du jeu de données de validation.\n",
    "\n",
    "On affiche la matrice de confusion pour le jeu de données de validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.26      0.12      0.16       119\n",
      "           0       0.29      0.18      0.22       342\n",
      "           1       0.75      0.88      0.81      1147\n",
      "\n",
      "    accuracy                           0.67      1608\n",
      "   macro avg       0.43      0.39      0.40      1608\n",
      "weighted avg       0.61      0.67      0.63      1608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Association des mots avec les classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_n_strongly_associated_features(vectoriser, model, n):\n",
    "    feature_names = np.array(vectoriser.get_feature_names_out())\n",
    "\n",
    "    for i in range(3):\n",
    "        class_name = model.classes_[i]\n",
    "        print(\"CLASSE {}\".format(class_name))\n",
    "        idx_coefs_sorted = model.coef_[i].argsort() # ordre croissant\n",
    "        print(\"Les dix variables ayant l'association négative la plus forte \" + \n",
    "              \"avec la classe {} :\\n{}\\n\".format(class_name,\n",
    "                                                 feature_names[idx_coefs_sorted[:n]]))\n",
    "        idx_coefs_sorted = idx_coefs_sorted[::-1] # ordre décroissant\n",
    "        print(\"Les dix variables ayant l'association positive la plus forte \" +\n",
    "              \"avec la classe {} :\\n{}\\n\"\n",
    "              .format(class_name,\n",
    "                      feature_names[idx_coefs_sorted[:n]]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2. Deuxième modèle de régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(multi_class='multinomial',\n",
    "                              solver='lbfgs').fit(X_train_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_lr.predict(X_valid_vectorized_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7189054726368159"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La performance est meilleure que le premier modèle de régression logistique. En effet, le modèle prédit correctement 71.21% des avis du jeu de données de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.03      0.06       119\n",
      "           0       0.51      0.06      0.10       342\n",
      "           1       0.72      0.99      0.84      1147\n",
      "\n",
      "    accuracy                           0.72      1608\n",
      "   macro avg       0.68      0.36      0.33      1608\n",
      "weighted avg       0.68      0.72      0.62      1608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3. Troisième modèle de régression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous créons un modèle de régression logistique avec le vectoriseur à unigrammes et bigrammes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(multi_class='multinomial', \n",
    "                              solver='lbfgs',\n",
    "                              max_iter=500).fit(X_train_vectorized_count_bigrams, \n",
    "                                                y_train)\n",
    "predictions_valid = model_lr.predict(X_valid_vectorized_count_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6741293532338308"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce modèle prédit correctement 67.41% des avis du jeu de données de validation.\\\n",
    "Sa performance est moins bonne que le deuxième modèle de régression logistique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.28      0.13      0.17       119\n",
      "           0       0.35      0.25      0.29       342\n",
      "           1       0.75      0.86      0.80      1147\n",
      "\n",
      "    accuracy                           0.67      1608\n",
      "   macro avg       0.46      0.41      0.42      1608\n",
      "weighted avg       0.63      0.67      0.65      1608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a plus d'erreur dans ce modèle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = SVC(kernel='linear', \n",
    "                C=0.1).fit(X_train_vectorized_count_bigrams, \n",
    "                           y_train)\n",
    "\n",
    "predictions_valid = model_svm.predict(X_valid_vectorized_count_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6735074626865671"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.21      0.13      0.16       119\n",
      "           0       0.32      0.15      0.21       342\n",
      "           1       0.74      0.88      0.81      1147\n",
      "\n",
      "    accuracy                           0.67      1608\n",
      "   macro avg       0.42      0.39      0.39      1608\n",
      "weighted avg       0.61      0.67      0.63      1608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Classification avec les stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, nous n'allons pas reproduire tous les tests de modèles essayés précdemment. Nous allons simplement tester les 2 modèles avec la meilleure accuracy obtenue, pour voir si le fait de supprimer les stopwords a un impact sur notre modèle. \\\n",
    "Nous allons donc utiliser le deuxième modèle de régression logistique ainsi que celui avec le classifieur baïésien naïf, dont les deux accuracy sont à 71% environ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Classifieur naïf baïésien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nb_sw = MultinomialNB().fit(X_train_vectorized_tfidf_sw, y_train)\n",
    "predictions_valid_sw = model_nb_sw.predict(X_valid_vectorized_tfidf_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7133084577114428"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclure pour ici mais j'ai pas les scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Deuxième modèle de régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr_sw = LogisticRegression(multi_class='multinomial',\n",
    "                              solver='lbfgs').fit(X_train_vectorized_tfidf_sw, y_train)\n",
    "predictions_valid_sw = model_lr.predict(X_valid_vectorized_tfidf_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7120646766169154"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premièrement, le temps d'exécution des modèles avec et sans stopwords est identiques.\\\n",
    "De plus, la suppression des \"stopwords\" dans les avis du jeu de données n'a pas d'impact significatif sur notre modèle. En effet, les accuracy sont quasi similaire (à 0.0005 près).\\\n",
    "Le modèle Bayésien naif est légèrement plus performant sans les stopwords.\n",
    "\n",
    "Etant donné qu'il n'y a pas de différence significative entre les modèles avec et sans stopwords au niveau des accuracy, cela nous conforte dans l'idée de ne pas tester tous les autres modèles en supprimant les stopwords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous avons choisi notre modèle, nous pouvons visualiser les 10 mots les plus probables dans chacune des classes (positivement et négativement). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_n_strongly_associated_features(vect_count, model_lr, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir quel le résultat est très logique. En effet, si nous prenons l'exemple de la classe 1, nous pouvons voir que les mots les moins probables d'y être associés sont par exemple \"déception\" ou \"déçue\", tandis qu eles mots étant le plus probable d'être cités sont \"magnifique\" ou encore \"excellent\". À REFAIRE EN FONCTION DES RÉSULTATS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À VOIR :\n",
    "\n",
    "- est-ce qu'on prend reader_review pour les train et les test ou est-ce qu'on prend la colonne des entités nommées ? ou une autre colonne ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons donc dire que le meilleur modèle est celui avec/sans les stopwords et celui qui utilise ??? (mettre meilleur modèle)\n",
    "\n",
    "Cependant, notre matrice de confusion est possiblement biaisée. En effet, certains de nos avis sont des \"résumés\" des livres, et ils on été classés dans la base de donnée comme non neutres. \n",
    "\n",
    "On a testé avec les bigram et trigram car intéressant dans notre cas \n",
    "\n",
    "On a pris la colonne avec les entités nommées car cela ne nous apporte rien de savoir le nom ??\n",
    "\n",
    "Si on teste avec une autre colonne : expliquer pourquoi \n",
    "\n",
    "\n",
    "\n",
    "Ce projet a donc été un réel plaisir à réaliser. Étant toutes les deux des grandes lectrices, nous avons pu rencontrer des livres que nous avons déjà lu. Cela nous a également fait découvrir d'autres livres, qui sont maintenant dans notre liste de lecture ! 😊 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Pour aller plus loin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Étude de la note en fonction de la polarité du commentaire laissé \n",
    "\n",
    "- **Personnalisation et recommandations:** Dans les systèmes de recommandation, la reconnaissance des entités nommées peut aider à comprendre les préférences des utilisateurs en identifiant les entités (comme des films, des livres, des lieux) mentionnées dans leurs interactions textuelles.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
