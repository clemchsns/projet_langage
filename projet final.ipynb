{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Margaux Bailleul 21906121\n",
    "Clémence CHESNAIS 21901191"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import regex as re\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "from nltk.stem.snowball import FrenchStemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy) (0.3.3)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy) (4.64.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: setuptools in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy) (63.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy) (1.26.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from jinja2->spacy) (2.0.1)\n",
      "Collecting fr-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from fr-core-news-sm==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.3.3)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.64.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.28.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.11.3)\n",
      "Requirement already satisfied: setuptools in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (63.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.26.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.3.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install -U spacy\n",
    "!python -m spacy download fr_core_news_sm\n",
    "import spacy\n",
    "nlp = spacy.load('fr_core_news_sm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>book_title</th>\n",
       "      <th>author</th>\n",
       "      <th>reader_review</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Le Démon de la Colline aux Loups</td>\n",
       "      <td>Dimitri Rouchon-Borie</td>\n",
       "      <td>Ce n'est pas le premier roman à aborder les th...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Simple</td>\n",
       "      <td>Marie-Aude Murail</td>\n",
       "      <td>Simple, alias Barnabé, est un jeune homme de 2...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>La plus secrète mémoire des hommes</td>\n",
       "      <td>Mohamed Mbougar Sarr</td>\n",
       "      <td>Pour écrire La plus secrète mémoire des hommes...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Trancher</td>\n",
       "      <td>Amélie Cordonnier</td>\n",
       "      <td>« La violence d'Aurélien est revenue. Par la f...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>La guerre d'Alan, tome 2</td>\n",
       "      <td>Emmanuel Guibert</td>\n",
       "      <td>Dans ce second album de La Guerre d’Alan, Emma...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                          book_title                 author  \\\n",
       "0           0    Le Démon de la Colline aux Loups  Dimitri Rouchon-Borie   \n",
       "1           1                              Simple      Marie-Aude Murail   \n",
       "2           2  La plus secrète mémoire des hommes   Mohamed Mbougar Sarr   \n",
       "3           3                            Trancher      Amélie Cordonnier   \n",
       "4           4            La guerre d'Alan, tome 2       Emmanuel Guibert   \n",
       "\n",
       "                                       reader_review  rating  label  \n",
       "0  Ce n'est pas le premier roman à aborder les th...     5.0      1  \n",
       "1  Simple, alias Barnabé, est un jeune homme de 2...     4.0      1  \n",
       "2  Pour écrire La plus secrète mémoire des hommes...     4.0      1  \n",
       "3  « La violence d'Aurélien est revenue. Par la f...     3.5      0  \n",
       "4  Dans ce second album de La Guerre d’Alan, Emma...     5.0      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import du fichier csv\n",
    "data = pd.read_csv('french_books_reviews.csv', sep=',')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce jeu de données nous disposons de 3 variables qualitatives et 2 variables quantitatives. \n",
    "Pour notre étude, nous avons le titre du livre, l'auteur, l'avis du lecteur, la note qu'il a attribué au livre ainsi qu'un label correspondant à la polarité de l'avis. Si l'avis est positif, le label vaut 1, s'il est neutre, il vaut 0 et s'il est négatif, il vaut -1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Statistiques descriptives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, nous commençons par regarder si la base de données contient des valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"reader_review\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13 lignes contiennent des valeurs manquantes. Nous décidons de les supprimer car elles ne représentent que 0.1% de la base de données.\n",
    "De plus, nous souhaitons étudiés les avis des clients, il n'y a donc pas d'intérêt à garder les lignes où il n'y a pas d'avis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['reader_review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous vérifions qu'il ne reste plus de ligne sans avis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"reader_review\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous regardons combien il y a d'avis pour chacune des polarités."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_reviews</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nb_reviews\n",
       "class            \n",
       " 1           6658\n",
       " 0           2129\n",
       "-1            858"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"label\"].value_counts()\n",
    "\n",
    "polarity_distribution= (pd.DataFrame.from_dict(Counter(data.label.values),\n",
    "                                             orient='index')\n",
    "                                  .rename(columns={0: 'nb_reviews'}))\n",
    "polarity_distribution.index.name = 'class'\n",
    "polarity_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce jeu de données, il y a 6670 positifs, 2129 neutres et 859 négatifs.\n",
    "\n",
    "Nous calculons le pourcentage d'avis pour chaque polarité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_reviews</th>\n",
       "      <th>pourcentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6658</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2129</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>858</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nb_reviews  pourcentage\n",
       "class                         \n",
       " 1           6658         0.69\n",
       " 0           2129         0.22\n",
       "-1            858         0.09"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarity_distribution['pourcentage'] = np.around(polarity_distribution.nb_reviews /\n",
    "                                                np.sum(polarity_distribution.nb_reviews),\n",
    "                                                2)\n",
    "polarity_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous représentons sur un graphique la distributions des polarités selon le nombre d'avis de livre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':\"Nombre d'avis par classe\"}, xlabel='class'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "polarity_distribution.plot(kind='bar', figsize=(8, 6), legend=False, \n",
    "                           title=\"Nombre d'avis par classe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous affichons les 5 premiers avis pour voir à quoi ressemble les données.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ce n'est pas le premier roman à aborder les thèmes lourds de l'inceste et de l'enfance martyre, mais il le fait avec une audace et un brio incomparables qui rendent ce livre marquant dans une vie de lecteur. On y sent à quel point l'auteur n'a pas cherché à \"faire quelque chose\", on ne sent jamais l'intention, on sent juste l'urgence, incandescente, à raconter la vérité d'un homme maltraité par la vie au point de dire à la nuit «  tu ne me feras pas peur j'ai plus de noir que toi dans mon enfance ».\n",
      "------------------------\n",
      "Simple, alias Barnabé, est un jeune homme de 22 ans qui a l’âge mental d’un enfant de 3 ans. Kléber, son frère de 17 ans, entre en terminale au lycée, mais décide de s’occuper lui-même de son frère. Leur mère étant morte et leur père refusant de s’encombrer de sa progéniture afin de vivre pleinement sa nouvelle vie, Kléber refuse d’abandonner son frère à Malicroix, l’institution où il dépérissait. Se mettant tant bien que mal à la recherche d’un appartement pour vivre avec son frère, Kléber tombe sur un logement en colocation où d’autres étudiants vont vite découvrir que vivre avec Simple n’est pas toujours… aisé !\n",
      "------------------------\n",
      "Pour écrire La plus secrète mémoire des hommes, Mohamed Mbougar Sarr s'est inspiré du destin brisé de Yambo Ouologuem, premier écrivain africain à remporter le Prix Renaudot en 1968 avec Le devoir de violence, à 28 ans. Il a connu la gloire, puis l’opprobre, finissant sa vie reclus, honni par ses pairs.\n",
      "------------------------\n",
      "« La violence d'Aurélien est revenue. Par la fenêtre, peut-être bien. C'est une surprise qui te foudroie. Depuis l'épisode des miettes, ses mots te fauchent comme une gifle. T'écorchent et t'humilient. Sa main ne se lève pas, mais de sa bouche les torgnoles tombent de nouveau. Et c'est une claque au coeur, chaque fois. Tu tournes le thermostat de la douche à fond. Mais cela ne suffit pas. Ça fait des jours que tu as froid. Il y a en toi quelque chose de glacé que rien ne parvient à réchauffer. Et dans ta tête, la phrase assassine qui a tué tes pauvres rêves de paix et de petits bonheurs tranquilles n'en finit plus de tourner. « Ferme ta gueule une bonne fois pour toutes, connasse, si tu veux pas que je la réduise en miettes. » »\n",
      "------------------------\n",
      "Dans ce second album de La Guerre d’Alan, Emmanuel Guibert m’a fait suivre à nouveau les pas de cet homme, Alan Cope, jeune soldat étasunien de vingt ans qui vient de débarquer en France.\n",
      "------------------------\n",
      "Evocation des guerres de religion, Les serviteurs inutiles romancent la vie des Feuillades, une famille périgourdine, dans la seconde moitié du XVI siècle endeuillée par les massacres de la Saint Barthélémy (24 aout 1572).\n",
      "------------------------\n",
      "Voilà un roman au sujet atypique nous venant de la Chine communiste, où les nouveaux milliardaires donnent lieu à de nouveaux conflits de classe avec le monde des domestiques qu'ils ont à leur service.\n",
      "------------------------\n",
      "Trois livres composent ce grand livre. Chaque livre se divise en plusieurs parties complétées par ce que Mohamed Mbouga Sarr, l’auteur, appelle des biographèmes, le tout étant un formidable hommage à Yambo Ouologuem, écrivain malien (1940 – 2017), lauréat du Prix Renaudot en 1968 avec Le Devoir de violence. Premier romancier africain à recevoir une telle récompense, il fut accusé ensuite de plagiat, meurtrissure qu’il ne surmontera jamais vraiment.\n",
      "------------------------\n",
      "♫Il est temps de venir à bout\n",
      "------------------------\n",
      "« C'est incroyable comme l'espoir plane tout près du désespoir ».\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in list(data['reader_review'][0:10]):\n",
    "    print(i)\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que certains avis ne sont pas réellement des avis mais un résumé du livre. Ces derniers devront être classé dans la catégorie neutre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2. Séparation des données\n",
    "\n",
    "Nous séparons les données en deux jeux de données : un jeu d'entrainement et un jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement : 6430\n",
      "Taille de l'ensemble de test : 3215\n"
     ]
    }
   ],
   "source": [
    "# On mélange les lignes du DataFrame\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# On utilise la fonction train_test_split pour diviser le DataFrame\n",
    "train_df, test_df = train_test_split(data, train_size=2/3, random_state=42)\n",
    "\n",
    "# On affiche les informations sur les ensembles d'entraînement et de test\n",
    "print(\"Taille de l'ensemble d'entraînement :\", len(train_df))\n",
    "print(\"Taille de l'ensemble de test :\", len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prétraitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Lemmatisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatiser un texte implique de réduire chaque mot à sa forme de base ou à son \"lemme\".\n",
    "Cela implique la suppression des variations grammaticales (comme les temps verbaux, les genres, les nombres, etc.) pour regrouper les mots qui ont la même signification de base\n",
    "\n",
    "La lemmatisation est souvent utilisée pour améliorer la précision de l'analyse en réduisant les variations de mots à leur forme canonique. Cela aide à regrouper les mots apparentés et à réduire la complexité lors de l'analyse textuelle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatisation(text):\n",
    "    text = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in text]\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On applique la lemmatisation sur les avis des livres des jeux de données d'aprentissage et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['lemme'] = train_df['reader_review'].fillna('')\n",
    "train_df['lemme'] = train_df['reader_review'].apply(lemmatisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "«    mais alors ! le père Noël exister -t il ?   » , pour - raton se demander à le lecture de ce guide qui donne envie de s’ offrir enfin à soi - même de cadeau utile ? pouvoir - être , mais ce qu’ il y avoir de certain , c’ être qu’ on y parler très peu de le mère Noël qui avoir perdre son châle .\n",
      "------------------------\n",
      "je retrouver avec beaucoup de joie l’ auteure , Marjane satrapi m’ avoir éblouir par son maturité dans Persépolis et je le retrouve tout aussi excellent dans Poulet à prune . on débarquer à Téhéran en 1958 , on retrouver le famille de l’ auteure dans ce opus mais pas de souci si vous n’ avoir pas lire Persépolis , c’ être un histoire inédit qu’ lui nous présente , toutefois je vous le conseil , il être magnifique .\n",
      "------------------------\n",
      "récit feuilletonnesque à souhait écrire par un duma jamais en manque de imagination . le aventure de Edmond Dantes être universel dans le mesure où lui pouvoir être délocaliser souher pour se inscrire dans ne importer quel pays . le auteur parl ici d vengeance et de droit à le justice . en se servir de son fortune , le protagoniste rétablit le ordre un chose et punir le scélérat en pointer leur turpitude . le personnage être bien sûr devenu de archétype au même titre que celui imaginer par Hugo . un classique !\n",
      "------------------------\n",
      "ce être un livre très agréable à lire . le auteur examin un foultitude de question concret , qui relever un mathématique simple , illustrer par un figure très clair . parmi le nombreux sujet aborder , je citer par exemple : le formation de embouteillage , le code informatique , le profil de piste de skateboard , le définition de jour de Pâques , le effet Magnus , le fort de Vauban , le forme de virage de tgv , le manière de paver , le extinction massif de espèce sur le terre , etc … Hervé Lehning expliquer bien et sans entrer dans le détail inutile . quelque « jeu » émailler le page . Bravo pour ce ouvrage !\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in list(train_df['lemme'][1:5]):\n",
    "    print(i)\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous faisons la même chose pour le jeu de données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['lemme'] = test_df['reader_review'].fillna('')\n",
    "test_df['lemme'] = test_df['reader_review'].apply(lemmatisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "et s’ il falloir choisir celui qui être sauver ?\n",
      "------------------------\n",
      "se attaquer à 667 page ( dense ) de ce biographie de Fouché pouvoir apparaître comme un challenge . mais le talent de historien de Emmanuel de Waresquiel avoir vite faire de donner le envie de parcourir ce ouvrage avec détermination !\n",
      "------------------------\n",
      "ce ouvrage plaire à petit comme à grand , à adepte de beal livre illustrer comme à sorcière et sorcier en herbe .\n",
      "------------------------\n",
      "livre fantastique remplir de émotion de début à le fin . le lecture de un chapitre me donner envie de connaître le suite . je avoir dévorer ce livre . par contre , quand le fin arriver , quel tristesse de laisser ce personnage . je avoir envier de continuer un petit bout de chemin avec lui .\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in list(test_df['lemme'])[1:5]:\n",
    "    print(i)\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Racine des mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous remplaçons les mots par leur racine. Cela permet de réduire la complexité lors de l'analyse textuelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_text(text):\n",
    "    tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "    stemmer = FrenchStemmer('french')\n",
    "    stems = [stemmer.stem(token) for token in tokenizer.tokenize(text)]\n",
    "    return ' '.join(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['stems'] = train_df['reader_review'].apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "« mais alor ! le per noël existera-t-il ? » , pour-raton se demand à la lectur de ce guid qui don envi de s ’ offrir enfin à soi-mêm des cadeau util ? peut-êtr , mais ce qu ’ il y a de certain , c ’ est qu ’ on y parl tres peu de la mer noël qui a perdu son châl .\n",
      "------------------------\n",
      "je retrouv avec beaucoup de joi l ’ auteur , marjan satrap m ’ avait éblou par sa matur dans persépol et je la retrouv tout auss excellent dans poulet aux prun . on débarqu à téhéran en 1958 , on retrouv la famill de l ’ auteur dans cet opus mais pas de souc si vous n ’ avez pas lu persépol , c ’ est une histoir inédit qu ’ elle nous présent , toutefois je vous le conseil , il est magnif .\n",
      "------------------------\n",
      "rec feuilletonnesqu à souh écrit par un dum jam en manqu d'imagin . les aventur d'edmond dant sont universel dans la mesur où elle peuvent être délocalis souh pour s'inscrir dans n'import quel pay . l'auteur parl ici d vengeanc et du droit à la justic . en se serv de sa fortun , le protagon rétabl l'ordr des chos et pun les scélérat en point leur turpitud . les personnag sont bien sûr devenus des archétyp au même titr que ceux imagin par hugo . un classiqu !\n",
      "------------------------\n",
      "c'est un livr tres agréabl à lir . l'auteur examin une foultitud de question concret , qui relèvent des mathémat simpl , illustr par des figur tres clair . parm les nombreux sujet abord , je cit par exempl : la format des embouteillag , les cod informat , le profil des pist de skateboard , la définit du jour de pâqu , l'effet magnus , les fort de vauban , la form de virag du tgv , les mani de pav , les extinct massiv des espec sur la terr , etc … herv lehning expliqu bien et san entrer dans les détail inutil . quelqu « jeux » émaillent les pag . bravo pour cet ouvrag !\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in list(train_df['stems'])[1:5]:\n",
    "    print(i)\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous faisons la même chose pour le jeu de données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['stems'] = test_df['reader_review'].apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "et s ’ il fall chois ceux qui seraient sauv ?\n",
      "------------------------\n",
      "s'attaqu aux 667 pag ( dens ) de cet biograph de fouch peut apparaîtr comm un challeng . mais le talent d'historien d'emmanuel de waresquiel a vit fait de don l'env de parcour cet ouvrag avec détermin !\n",
      "------------------------\n",
      "cet ouvrag plair aux petit comm aux grand , aux adept de beau livr illustr comm aux sorci et sorci en herb .\n",
      "------------------------\n",
      "livr fantast rempl d'émot du début à la fin . la lectur d'un chapitr me don envi de connaîtr la suit . j'ai dévor ce livr . par contr , quand la fin arriv , quel tristess de laiss ces personnag . j'av envi de continu un pet bout de chemin avec eux .\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in list(test_df['stems'][1:5]):\n",
    "    print(i)\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Etiquetage morphosyntaxique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_words_with_pos_tag(text):\n",
    "    text = nlp(text)\n",
    "    return ' '.join([token.pos_ for token in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['pos'] = train_df['reader_review'].apply(replace_words_with_pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>book_title</th>\n",
       "      <th>author</th>\n",
       "      <th>reader_review</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>lemme</th>\n",
       "      <th>stems</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3855</th>\n",
       "      <td>6198</td>\n",
       "      <td>Le guide du Noël parfait</td>\n",
       "      <td>Docteur Guido</td>\n",
       "      <td>«  Mais alors ! Le père Noël existera-t-il ? »...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>«    mais alors ! le père Noël exister -t il ?...</td>\n",
       "      <td>« mais alor ! le per noël existera-t-il ? » , ...</td>\n",
       "      <td>ADJ SPACE CCONJ ADV PUNCT DET NOUN PROPN AUX P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>1844</td>\n",
       "      <td>Poulet aux prunes</td>\n",
       "      <td>Marjane Satrapi</td>\n",
       "      <td>Je retrouve avec beaucoup de joie l’auteure, M...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>je retrouver avec beaucoup de joie l’ auteure ...</td>\n",
       "      <td>je retrouv avec beaucoup de joi l ’ auteur , m...</td>\n",
       "      <td>PRON VERB ADP ADV ADP VERB ADJ VERB PUNCT PROP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>8277</td>\n",
       "      <td>Le comte de Monte-Cristo, tome 1</td>\n",
       "      <td>Alexandre Dumas</td>\n",
       "      <td>Récit feuilletonnesque à souhait écrit par un ...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>récit feuilletonnesque à souhait écrire par un...</td>\n",
       "      <td>rec feuilletonnesqu à souh écrit par un dum ja...</td>\n",
       "      <td>NOUN ADJ ADP NOUN VERB ADP DET NOUN ADV ADP NO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>4924</td>\n",
       "      <td>Questions de maths sympas : Pour M. Et Mme Tou...</td>\n",
       "      <td>Hervé Lehning</td>\n",
       "      <td>C'est un livre très agréable à lire. L'auteur ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>ce être un livre très agréable à lire . le aut...</td>\n",
       "      <td>c'est un livr tres agréabl à lir . l'auteur ex...</td>\n",
       "      <td>PRON AUX DET NOUN ADV ADJ ADP VERB PUNCT DET N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                         book_title  \\\n",
       "3855        6198                           Le guide du Noël parfait   \n",
       "2514        1844                                  Poulet aux prunes   \n",
       "5440        8277                   Le comte de Monte-Cristo, tome 1   \n",
       "2917        4924  Questions de maths sympas : Pour M. Et Mme Tou...   \n",
       "\n",
       "               author                                      reader_review  \\\n",
       "3855    Docteur Guido  «  Mais alors ! Le père Noël existera-t-il ? »...   \n",
       "2514  Marjane Satrapi  Je retrouve avec beaucoup de joie l’auteure, M...   \n",
       "5440  Alexandre Dumas  Récit feuilletonnesque à souhait écrit par un ...   \n",
       "2917    Hervé Lehning  C'est un livre très agréable à lire. L'auteur ...   \n",
       "\n",
       "      rating  label                                              lemme  \\\n",
       "3855     5.0      1  «    mais alors ! le père Noël exister -t il ?...   \n",
       "2514     4.5      1  je retrouver avec beaucoup de joie l’ auteure ...   \n",
       "5440     4.5      1  récit feuilletonnesque à souhait écrire par un...   \n",
       "2917     4.0      1  ce être un livre très agréable à lire . le aut...   \n",
       "\n",
       "                                                  stems  \\\n",
       "3855  « mais alor ! le per noël existera-t-il ? » , ...   \n",
       "2514  je retrouv avec beaucoup de joi l ’ auteur , m...   \n",
       "5440  rec feuilletonnesqu à souh écrit par un dum ja...   \n",
       "2917  c'est un livr tres agréabl à lir . l'auteur ex...   \n",
       "\n",
       "                                                    pos  \n",
       "3855  ADJ SPACE CCONJ ADV PUNCT DET NOUN PROPN AUX P...  \n",
       "2514  PRON VERB ADP ADV ADP VERB ADJ VERB PUNCT PROP...  \n",
       "5440  NOUN ADJ ADP NOUN VERB ADP DET NOUN ADV ADP NO...  \n",
       "2917  PRON AUX DET NOUN ADV ADJ ADP VERB PUNCT DET N...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous faisons la même chose pour le jeu de données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['pos'] = test_df['reader_review'].apply(replace_words_with_pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>book_title</th>\n",
       "      <th>author</th>\n",
       "      <th>reader_review</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>lemme</th>\n",
       "      <th>stems</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>6591</td>\n",
       "      <td>La fin des temps</td>\n",
       "      <td>Jean-Louis Vincent (II)</td>\n",
       "      <td>Et s’il fallait choisir ceux qui seraient sauv...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>et s’ il falloir choisir celui qui être sauver ?</td>\n",
       "      <td>et s ’ il fall chois ceux qui seraient sauv ?</td>\n",
       "      <td>CCONJ PRON PRON VERB NOUN PRON PRON AUX VERB P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6056</th>\n",
       "      <td>3561</td>\n",
       "      <td>Fouché : Les silences de la pieuvre</td>\n",
       "      <td>Emmanuel de Waresquiel</td>\n",
       "      <td>S'attaquer aux 667 pages (denses) de cette bio...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>se attaquer à 667 page ( dense ) de ce biograp...</td>\n",
       "      <td>s'attaqu aux 667 pag ( dens ) de cet biograph ...</td>\n",
       "      <td>PRON VERB ADP NUM NOUN PUNCT ADJ PUNCT ADP DET...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5020</th>\n",
       "      <td>4996</td>\n",
       "      <td>Mon grand grimoire de petite sorcière</td>\n",
       "      <td>Anne-Sophie Schlick</td>\n",
       "      <td>Cet ouvrage plaira aux petits comme aux grands...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>ce ouvrage plaire à petit comme à grand , à ad...</td>\n",
       "      <td>cet ouvrag plair aux petit comm aux grand , au...</td>\n",
       "      <td>DET NOUN VERB ADP ADJ ADP ADP NOUN PUNCT ADP N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4397</th>\n",
       "      <td>5319</td>\n",
       "      <td>T'embrasser sous la neige</td>\n",
       "      <td>Emily Blaine</td>\n",
       "      <td>livre fantastique rempli d'émotions du début à...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>livre fantastique remplir de émotion de début ...</td>\n",
       "      <td>livr fantast rempl d'émot du début à la fin . ...</td>\n",
       "      <td>NOUN ADJ VERB ADP NOUN ADP NOUN ADP DET NOUN P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                             book_title  \\\n",
       "1543        6591                       La fin des temps   \n",
       "6056        3561    Fouché : Les silences de la pieuvre   \n",
       "5020        4996  Mon grand grimoire de petite sorcière   \n",
       "4397        5319              T'embrasser sous la neige   \n",
       "\n",
       "                       author  \\\n",
       "1543  Jean-Louis Vincent (II)   \n",
       "6056   Emmanuel de Waresquiel   \n",
       "5020      Anne-Sophie Schlick   \n",
       "4397             Emily Blaine   \n",
       "\n",
       "                                          reader_review  rating  label  \\\n",
       "1543  Et s’il fallait choisir ceux qui seraient sauv...     5.0      1   \n",
       "6056  S'attaquer aux 667 pages (denses) de cette bio...     4.0      1   \n",
       "5020  Cet ouvrage plaira aux petits comme aux grands...     4.5      1   \n",
       "4397  livre fantastique rempli d'émotions du début à...     5.0      1   \n",
       "\n",
       "                                                  lemme  \\\n",
       "1543   et s’ il falloir choisir celui qui être sauver ?   \n",
       "6056  se attaquer à 667 page ( dense ) de ce biograp...   \n",
       "5020  ce ouvrage plaire à petit comme à grand , à ad...   \n",
       "4397  livre fantastique remplir de émotion de début ...   \n",
       "\n",
       "                                                  stems  \\\n",
       "1543      et s ’ il fall chois ceux qui seraient sauv ?   \n",
       "6056  s'attaqu aux 667 pag ( dens ) de cet biograph ...   \n",
       "5020  cet ouvrag plair aux petit comm aux grand , au...   \n",
       "4397  livr fantast rempl d'émot du début à la fin . ...   \n",
       "\n",
       "                                                    pos  \n",
       "1543  CCONJ PRON PRON VERB NOUN PRON PRON AUX VERB P...  \n",
       "6056  PRON VERB ADP NUM NOUN PUNCT ADJ PUNCT ADP DET...  \n",
       "5020  DET NOUN VERB ADP ADJ ADP ADP NOUN PUNCT ADP N...  \n",
       "4397  NOUN ADJ VERB ADP NOUN ADP NOUN ADP DET NOUN P...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etant donné que notre fonction de lemmatisation est assez longue a exécuter, nous avons décidé de sauvegarder les jeux de données de test et d'apprentissage dans des fichiers pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde\n",
    "train_df.to_pickle('train.pkl')\n",
    "test_df.to_pickle('test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Entités nommées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner(text):\n",
    "    text = nlp(text)\n",
    "    new_text = []\n",
    "    for token in text:\n",
    "        if token.ent_iob_ == \"O\":\n",
    "            new_text.append(token.text)\n",
    "        elif token.ent_iob_ == \"B\":\n",
    "            new_text.append(token.ent_type_)\n",
    "        # Si l'entité comprend plusieurs mot on ne répète pas l'étiquette\n",
    "        else:\n",
    "            continue\n",
    "    return ' '.join(new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour expliquer cette fonction, nous prenons l'exemple avec la phrase suivante :\n",
    "\"Elle vit à Paris et travaille chez Google. Elle a rencontré John Doe à New York.\"\n",
    "\n",
    "La fontion pour chaque mot donne le résultat suivant :\n",
    "\n",
    "- \"Elle\" : \"O\" (Outside), car ce mot ne fait pas partie d'une entité nommée.\n",
    "\n",
    "- \"vit\" : \"O\" (Outside), pas une entité nommée.\n",
    "\n",
    "- \"à\" : \"O\" (Outside), pas une entité nommée.\n",
    "\n",
    "- \"Paris\" :\"B\" (Beginning) et ent_type_ = \"LIEU\" , car c'est le début d'une entité nommée de type \"LIEU\".\n",
    "\n",
    "- \"et\" : \"O\" (Outside), pas une entité nommée.\n",
    "\n",
    "- \"travaille\" : \"O\" (Outside), pas une entité nommée.\n",
    "\n",
    "- \"chez\" : \"O\" (Outside), pas une entité nommée.\n",
    "\n",
    "- \"Google\" : \"B\" (Beginning) et ent_type_ = \"ORGANISATION\", car c'est le début d'une entité nommée de type \"ORGANISATION\".\n",
    "\n",
    "- \".\" : \"O\" (Outside), pas une entité nommée.\n",
    "\n",
    "- \"Elle\" : \"O\" (Outside), pas une entité nommée.\n",
    "\n",
    "- \"a\" : \"O\" (Outside), pas une entité nommée.\n",
    "\n",
    "- \"rencontré\" : \"O\" (Outside), pas une entité nommée.\n",
    "\n",
    "- \"John\" : \"B\" (Beginning) et ent_type_ = \"PERSONNE\", car c'est le début d'une entité nommée de type \"PERSONNE\".\n",
    "\n",
    "- \"Doe\" : \"I\" (Inside) et ent_type_ = \"PERSONNE\", car c'est la suite d'une entité nommée de type \"PERSONNE\".\n",
    "\n",
    "- \"à\" : \"O\" (Outside), pas une entité nommée.\n",
    "\n",
    "- \"New\" : \"B\" (Beginning) et ent_type_ = \"LIEU\", car c'est le début d'une entité nommée de type \"LIEU\".\n",
    "\n",
    "- \"York\" : \"I\" (Inside) et ent_type_ = \"LIEU\", car c'est la suite d'une entité nommée de type \"LIEU\".\n",
    "\n",
    "- \".\" : \"O\" (Outside), pas une entité nommée.\n",
    "\n",
    "\n",
    "Les entités de type I ne sont pas affichées.\n",
    "Pour les mots de type B, ils seront remplacées par le type de l'entité nommée. Par exemple, \"Paris\" sera remplacé par \"LIEU\".\n",
    "\n",
    "On aura donc la phrase suivante :\n",
    "\n",
    "\"Elle vit à LIEU et travaille chez ORGANISATION. Elle a rencontré PERSONNE à LIEU.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous appliquons cette fonction sur les jeux de données d'apprentissage et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['entites_nommees'] = train_df['reader_review'].apply(ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "«    Mais alors ! Le père MISC existera -t -il ?   » , pour - raton se demander à la lecture de ce guide qui donne envie de PER offrir enfin à soi - même des cadeaux utiles ? Peut - être , mais ce qu’ il y a de certain , MISC est LOC on y parle très peu de la mère MISC qui a perdu son châle .\n",
      "------------------------\n",
      "Je retrouve avec beaucoup de joie l’ auteure , MISC PER avait ébloui par sa maturité dans LOC et je la retrouve tout aussi excellent dans LOC aux prunes . On débarque à LOC en 1958 , on retrouve la famille de LOC auteure dans cet opus mais pas de soucis si vous PER avez pas lu LOC , MISC est une histoire inédite qu’ elle nous présente , toutefois je vous le conseil , il est magnifique .\n",
      "------------------------\n",
      "Récit feuilletonnesque à souhait écrit par un PER jamais en manque d' imagination . Les aventures d' PER sont universelles dans la mesure où elles peuvent être délocalisées souhait pour s' inscrire dans n' importe quel pays . L' auteur parle ici d vengeance et du droit à la justice . En se servant de sa fortune , le protagoniste rétablit l' ordre des choses et punit les scélérats en pointant leurs turpitudes . Les personnages sont bien sûr devenus des archétypes au même titre que ceux imaginés par PER . Un classique !\n",
      "------------------------\n",
      "C' est un livre très agréable à lire . L' auteur examine une foultitude de questions concrètes , qui relèvent des mathématiques simples , illustrées par des figures très claires . Parmi les nombreux sujets abordés , je citerai par exemple : la formation des embouteillages , les codes informatiques , le profil des pistes de skateboard , la définition du jour de MISC , l' effet PER , les forts de PER , la forme de virages du MISC , les manières de paver , les extinctions massives des espèces sur LOC , etc … PER explique bien et sans entrer dans les détails inutiles . Quelques « jeux » émaillent les pages . PER pour cet ouvrage !\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in list(train_df['entites_nommees'][1:5]):\n",
    "    print(i)\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['entites_nommees'] = test_df['reader_review'].apply(ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Et LOC il fallait choisir ceux qui seraient sauvés ?\n",
      "------------------------\n",
      "S' attaquer aux 667 pages ( denses ) de cette biographie de PER peut apparaître comme un challenge . Mais le talent d' historien d' PER a vite fait de donner l' envie de parcourir cet ouvrage avec détermination !\n",
      "------------------------\n",
      "Cet ouvrage plaira aux petits comme aux grands , aux adeptes de beaux livres illustrés comme aux sorcières et sorciers en herbe .\n",
      "------------------------\n",
      "livre fantastique rempli d' émotions du début à la fin . la lecture d' un chapitre me donnait envie de connaître la suite . j' ai dévoré ce livre . par contre , quand la fin arrive , quelle tristesse de laisser ces personnages . j' avais envie de continuer un petit bout de chemin avec eux .\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in list(test_df['entites_nommees'][1:5]):\n",
    "    print(i)\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde\n",
    "train_df.to_pickle('train.pkl')\n",
    "test_df.to_pickle('test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Traitement des URLS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous remplaçons les URLS par un mot fictif "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remplacer_url(text, url_replacement='urlexpr'):\n",
    "    text = re.sub(r'https?:\\S+', url_replacement, text) # http://t.co/eFKkE9W0GI\n",
    "    text = re.sub(r'\\bwww\\.\\S+', url_replacement, text) # www.example.com\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['sans_url'] = train_df['reader_review'].apply(remplacer_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "«  Mais alors ! Le père Noël existera-t-il ? », pour-raton se demander à la lecture de ce guide qui donne envie de s’offrir enfin à soi-même des cadeaux utiles ? Peut-être, mais ce qu’il y a de certain, c’est qu’on y parle très peu de la mère Noël qui a perdu son châle.\n",
      "------------------------\n",
      "Je retrouve avec beaucoup de joie l’auteure, Marjane Satrapi m’avait ébloui par sa maturité dans Persépolis et je la retrouve tout aussi excellent dans Poulet aux prunes. On débarque à Téhéran en 1958, on retrouve la famille de l’auteure dans cet opus mais pas de soucis si vous n’avez pas lu Persépolis, c’est une histoire inédite qu’elle nous présente, toutefois je vous le conseil, il est magnifique.\n",
      "------------------------\n",
      "Récit feuilletonnesque à souhait écrit par un Dumas jamais en manque d'imagination. Les aventures d'Edmond Dantes sont universelles dans la mesure où elles peuvent être délocalisées souhait pour s'inscrire dans n'importe quel pays. L'auteur parle ici d vengeance et du droit à la justice. En se servant de sa fortune, le protagoniste rétablit l'ordre des choses et punit les scélérats en pointant leurs turpitudes. Les personnages sont bien sûr devenus des archétypes au même titre que ceux imaginés par Hugo. Un classique !\n",
      "------------------------\n",
      "C'est un livre très agréable à lire. L'auteur examine une foultitude de questions concrètes, qui relèvent des mathématiques simples, illustrées par des figures très claires. Parmi les nombreux sujets abordés, je citerai par exemple: la formation des embouteillages, les codes informatiques, le profil des pistes de skateboard, la définition du jour de Pâques, l'effet Magnus, les forts de Vauban, la forme de virages du TGV, les manières de paver, les extinctions massives des espèces sur la Terre, etc… Hervé Lehning explique bien et sans entrer dans les détails inutiles. Quelques « jeux » émaillent les pages. Bravo pour cet ouvrage !\n",
      "------------------------\n",
      "Ce livre est un vrai coup de cœur, je ne pouvais plus lâcher ma liseuse quand je reprenais ma lecture (j'ai même dû cacher ma liseuse pour pouvoir réviser mes exams correctement 😅)\n",
      "------------------------\n",
      "Qui n’a jamais connu le moindre échec dans sa vie ? A moins d’être un optimiste invétéré, celui-ci peut parfois être difficile à digérer. Et si vous les voyiez plutôt comme une chance ? Celle de mieux se connaître, de se réinventer, une invitation à voir ce que vous ne voulions pas, une chance de s’arrêter dans une vie trop hâtive, une leçon d’humilité, une nouvelle manière d’oser vivre pleinement et de prendre des risques… La liste est longue.\n",
      "------------------------\n",
      "Voilà un roman que l’on pourrait qualifier de daté. Nous sommes dans une époque révolue, celle des gentlemen britanniques à la conquête du Monde et des cœurs sous le règne de Victoria.\n",
      "------------------------\n",
      "il s’agit sûrement de ma révélation de l’année 2021. En rentrant dans ma librairie habituelle, je cherchais un livre historique accessible. je suis ressorti avec un chef d’œuvre. il est très accessible et décrit parfaitement les civilisations de cette période, avant l’invention de la poudre, où tout les peuples sont à peu près égaux. Il s’agit de regarder le monde, ainsi que l’économie qui en découle, via le prisme de chaque civilisation.\n",
      "------------------------\n",
      "beaucoup d’informations dans ce livre-documentaire. L’auteur y détaille minutieusement le sort de tous ces anciens nazis, dont l’expérience acquise sous les drapeaux du troisième Reich, ont beaucoup intéressé les puissances de l’après-guerre, toutes entières mobilisées pour la guerre froide qui s’annonçait. Tortionnaires, gestionnaires de camp, manipulateurs d’informations, commandos en rupture de ban, ils ont été nombreux à vivre une vie respectable et à mourir de vieillesse dans leurs lits, ce qui n’a pas été le sort de leurs milliers de victimes. Très instructif mais un peu désespérant sur la notion toute relative de justice.\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in list(train_df[\"sans_url\"][1:10]):\n",
    "    print(i)\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous faisons la même chose pour le jeu de données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['sans_url'] = test_df['reader_review'].apply(remplacer_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Et s’il fallait choisir ceux qui seraient sauvés ?\n",
      "------------------------\n",
      "S'attaquer aux 667 pages (denses) de cette biographie de Fouché peut apparaître comme un challenge. Mais le talent d'historien d'Emmanuel de Waresquiel a vite fait de donner l'envie de parcourir cet ouvrage avec détermination!\n",
      "------------------------\n",
      "Cet ouvrage plaira aux petits comme aux grands, aux adeptes de beaux livres illustrés comme aux sorcières et sorciers en herbe.\n",
      "------------------------\n",
      "livre fantastique rempli d'émotions du début à la fin. la lecture d'un chapitre me donnait envie de connaître la suite. j'ai dévoré ce livre. par contre, quand la fin arrive, quelle tristesse de laisser ces personnages. j'avais envie de continuer un petit bout de chemin avec eux.\n",
      "------------------------\n",
      "Super roman de Noel, qui en plus se passe en Martinique du coup il fait chaud. Les personnages sont profonds et bien travailler. Il y a de la bienveillance et du consentement entre les protagonistes, qui est clairement affichés et ca fait du bien dans une romance. On se doute de l'histoire mais c'est tellement bien écrits qu'on veut savoir comment et pourquoi. J'ai bien aimé l'alterne des points de vue ainsi que les retour dans le passé.\n",
      "------------------------\n",
      "A son retour de la guerre en Europe, Sam Hall, jeune citoyen de Mohawk (ville imaginaire de l’état de New York), n’a qu’une envie : boire avec les copains, jouer aux courses, profiter de la vie. C’est plus que n’en peut supporter sa jeune épouse Jenny, surtout après la naissance de leur fils Ned. Elle demande le divorce, il le refuse et s’en prend au malheureux avocat de Jenny (une scène d’anthologie !).\n",
      "------------------------\n",
      "Elles sont cinq amies dans une petite ville, au milieu des années 80. Des rêves, des désillusions déjà…\n",
      "------------------------\n",
      "Comme une urgence.\n",
      "------------------------\n",
      "La guerre du Vietnam fut un conflit interminable qui dura trente ans. Tout d'abord avec la France qui envoya 150 000 hommes et quitta le terrain après la défaite de Dien-Bien-Phu puis avec les États-Unis qui déployèrent un million de combattants et ne lésinèrent sur aucun moyen, même les plus barbares, avant d'abandonner en 1975. Ainsi larguèrent-ils sur le pays la bagatelle de 7 millions de tonnes de bombes de toutes sortes (dont le napalm, le phosphore blanc et les obus à fragmentation) soit trois fois plus que tout ce qui fut déversé sur l'Europe et l'Asie au cours de la seconde guerre mondiale. L'arme la plus terrible fut l'Agent orange, un défoliant à base de dioxine, fabriqué par Dow Chemicals, Monsanto et quelques autres, qui transforma des millions d'hectares de jungle en désert pour pouvoir plus aisément débusquer les soldats Viet-Congs. Au total, cent millions de litres de ce poison furent pulvérisés sur le pays, polluant les terres, les rizières, les cours d'eau et les nappes phréatiques pour des années. Un biocide dantesque sans oublier un coût humain monstrueux. 4,8 millions de Vietnamiens et des dizaines de milliers de GI's y furent exposés et développèrent toutes sortes de cancers et autres maladies graves. Les femmes se mirent à accoucher de bébés mort-nés, difformes, hydrocéphales, aveugles, sans bras, sans jambes, etc. Et cela continue encore et encore, sans doute tant que tout le pays ne sera pas dépollué !\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in list(test_df[\"sans_url\"][1:10]):\n",
    "    print(i)\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6430, 11), (3215, 11))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde\n",
    "train_df.to_pickle('train.pkl')\n",
    "test_df.to_pickle('test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Suppression de certains mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('train.pkl')\n",
    "test_df = pd.read_pickle('test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La suppression de certains mots comme les \"mots vides\", c'est-à-dire les mots qui n'apportent pas d'information pour la classification, permettent de se focaliser sur les mots les plus importants. Par exemple, les mots \"et\", \"car\", \"le\", \"la\"... n'apportent pas d'information. \n",
    "De plus, les modèles d'analyse de sentiments peuvent être sensibles à la dimensionnalité élevée des données. \n",
    "\n",
    "En réduisant le vocabulaire, on réduit le nombre de mots que le modèle doit prendre en compte, ce qui peut améliorer l'efficacité de l'apprentissage et la vitesse d'entraînement.\n",
    "Certains mots peuvent apparaître rarement ou être spécifiques à des documents particuliers, ce qui peut introduire du bruit dans le modèle. \n",
    "Par ailleurs, en se concentrant sur les termes les plus fréquents et les plus informatifs, le modèle peut se généraliser plus efficacement à de nouveaux textes. Cela peut également contribuer à éviter le surajustement aux données d'entraînement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle', 'en', 'et', 'eux', 'il', 'ils', 'je', 'la', 'le', 'les', 'leur', 'lui', 'ma', 'mais', 'me', 'même', 'mes', 'moi', 'mon', 'ne', 'nos', 'notre', 'nous', 'on', 'ou', 'par', 'pas', 'pour', 'qu', 'que', 'qui', 'sa', 'se', 'ses', 'son', 'sur', 'ta', 'te', 'tes', 'toi', 'ton', 'tu', 'un', 'une', 'vos', 'votre', 'vous', 'c', 'd', 'j', 'l', 'à', 'm', 'n', 's', 't', 'y', 'été', 'étée', 'étées', 'étés', 'étant', 'étante', 'étants', 'étantes', 'suis', 'es', 'est', 'sommes', 'êtes', 'sont', 'serai', 'seras', 'sera', 'serons', 'serez', 'seront', 'serais', 'serait', 'serions', 'seriez', 'seraient', 'étais', 'était', 'étions', 'étiez', 'étaient', 'fus', 'fut', 'fûmes', 'fûtes', 'furent', 'sois', 'soit', 'soyons', 'soyez', 'soient', 'fusse', 'fusses', 'fût', 'fussions', 'fussiez', 'fussent', 'ayant', 'ayante', 'ayantes', 'ayants', 'eu', 'eue', 'eues', 'eus', 'ai', 'as', 'avons', 'avez', 'ont', 'aurai', 'auras', 'aura', 'aurons', 'aurez', 'auront', 'aurais', 'aurait', 'aurions', 'auriez', 'auraient', 'avais', 'avait', 'avions', 'aviez', 'avaient', 'eut', 'eûmes', 'eûtes', 'eurent', 'aie', 'aies', 'ait', 'ayons', 'ayez', 'aient', 'eusse', 'eusses', 'eût', 'eussions', 'eussiez', 'eussent']\n"
     ]
    }
   ],
   "source": [
    "sw = nltk.corpus.stopwords.words('french')\n",
    "print(sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous appliquerons ce corpus de mots vides à nos jeux de données d'apprentissage et de test dans la suite de notre étude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Calcul des valeurs des descripteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Séparation du jeu de données d'entrainement en 2 jeux de données\n",
    "\n",
    "Nous séparons le jeu de données d'entrainement en 2 jeux de données : un jeu de données d'entrainement et un jeu de données de validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_df['reader_review'],\n",
    "                                                      train_df['label'],\n",
    "                                                      train_size=0.75,\n",
    "                                                      random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4822,), (1608,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4822,), (1608,))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1871    1\n",
       "7654   -1\n",
       "1863   -1\n",
       "4761    1\n",
       "6294    0\n",
       "       ..\n",
       "2606    1\n",
       "5466    1\n",
       "3191    1\n",
       "7438    1\n",
       "5113    1\n",
       "Name: label, Length: 4822, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le jeu de données tests, on met la variable label dans un objet \"y_test\" et la colonne \"reader_review\" dans un objet \"X_test\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = test_df['reader_review'], test_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Présence ou absence de certains mots : binaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_count = CountVectorizer(binary=True, stop_words=sw, strip_accents='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['etaient', 'etais', 'etait', 'etant', 'etante', 'etantes', 'etants', 'ete', 'etee', 'etees', 'etes', 'etiez', 'etions', 'eumes', 'eutes', 'fumes', 'futes', 'meme'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(binary=True,\n",
       "                stop_words=['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de',\n",
       "                            'des', 'du', 'elle', 'en', 'et', 'eux', 'il', 'ils',\n",
       "                            'je', 'la', 'le', 'les', 'leur', 'lui', 'ma',\n",
       "                            'mais', 'me', 'même', 'mes', 'moi', 'mon', 'ne',\n",
       "                            'nos', ...],\n",
       "                strip_accents='unicode')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_count.fit(X_train)\n",
    "bin_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4822x22488 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 132878 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized_bin = bin_count.transform(X_train)\n",
    "X_train_vectorized_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_vectorized_bin = bin_count.transform(X_valid)\n",
    "X_test_vectorized_bin = bin_count.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1608x22488 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 39733 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_vectorized_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATTENTION !!! ON EN FAIT QUOI DE ÇA ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Numérique discret : décompte d'occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction CountVectorizer permet de compter le nombre d'occurences de chaque mot dans chaque avis. Elle transforme une liste de textes en une représentation numérique utilisable pour des algorithmes d'apprentissage automatique.\n",
    "\n",
    "Le processus de fit consiste à analyser le texte pour déterminer les mots uniques présents dans X_train et à créer une représentation vectorielle de ces mots. Chaque texte sera représenté comme un vecteur où chaque élément correspond à la fréquence d'apparition de chaque mot du vocabulaire dans ce texte.\n",
    "\n",
    "Ainsi, cela créé un objet \"CountVectorizer\" qui contient le vocabulaire de tous les mots de tous les avis.\\ Cet objet est appelé \"vect_count\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_count = CountVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche les 50 premiers noms des mots utilisés pour créer la représentation vectorielle des textes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['000', '02', '03', '08', '10', '100', '1000', '1078', '109', '11',\n",
       "       '112', '115', '12', '1200', '121', '125', '12ans', '12heures',\n",
       "       '13', '130', '130kg', '130p', '14', '140', '141', '1415', '1425',\n",
       "       '144', '14ans', '15', '150', '1518', '153', '15jours', '16', '160',\n",
       "       '1600', '1604', '1613', '1615', '164', '165', '1664', '1665',\n",
       "       '1691', '16ème', '17', '173', '1750', '1756'], dtype=object)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_count.get_feature_names_out()[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche les 50 derniers noms des mots utilisés pour créer la représentation vectorielle des textes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['évoquée', 'évoquées', 'évoqués', 'évènement', 'évènementielle',\n",
       "       'évènements', 'événement', 'événements', 'êkho', 'êtes', 'être',\n",
       "       'êtres', 'île', 'îles', 'ïnes', 'ôshi', 'ôte', 'örn', 'œdipe',\n",
       "       'œdipienne', 'œil', 'œils', 'œuf', 'œufs', 'œuvre', 'œuvrent',\n",
       "       'œuvres', 'œuvré', 'достоевский', 'михайлович', 'фёдор', '日光流年',\n",
       "       '阎连科', '𝐻𝑒𝑎𝑟𝑡𝑠', '𝐽𝑒', '𝑁𝑜𝑒', '𝑇𝑎𝑖𝑛𝑡𝑒𝑑', '𝑎𝑖𝑚𝑒𝑟', '𝑓𝑒𝑟𝑎𝑖𝑠', '𝑡𝑒',\n",
       "       '𝗟𝗮', '𝗰𝗵𝗼𝘀𝗲', '𝗱𝗶𝘀𝗽𝗼𝘀𝗲𝘀', '𝗲𝗻', '𝗲𝘁', '𝗽𝗿𝗼𝗽𝗼𝘀𝗲', '𝗾𝘂𝗲𝗹𝗾𝘂𝗲', '𝘁𝗲',\n",
       "       '𝘁𝘂', '𝘃𝗶𝗲'], dtype=object)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_count.get_feature_names_out()[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23492"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect_count.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi, nous créons une représentation vectorielle des données d'entraînement en se basant sur le vocabulaire établi précédemment. \n",
    "\n",
    "Donc, cette opération convertit les données textuelles en une matrice numérique où chaque ligne correspond à un texte et chaque colonne correspond à la fréquence d'un mot spécifique dans ce texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4822x23492 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 192491 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized_count = vect_count.transform(X_train)\n",
    "X_train_vectorized_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train_count est une matrice de taille (n_train=4822, n_features=23492) où n_train est le nombre de textes dans le jeu de données d'entraînement et n_features est le nombre de mots dans le vocabulaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous faisons la même chose pour le jeu de données de validation et de test :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_vectorized_count = vect_count.transform(X_valid)\n",
    "X_test_vectorized_count = vect_count.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous créons un autre objet CountVectorizer mais cette fois-ci, nous posons certaines conditions : le mot doit apparaitre au moins 5 fois dans les documents pour être inclus dans le vocabulaie. De plus, les mots seront des unigrammes et des bigrammes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_count_bigrams = CountVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)\n",
    "X_train_vectorized_count_bigrams = vect_count_bigrams.transform(X_train)\n",
    "X_valid_vectorized_count_bigrams = vect_count_bigrams.transform(X_valid)\n",
    "X_test_vectorized_count_bigrams = vect_count_bigrams.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10483"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect_count_bigrams.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le nombre de mots dans le vocabulaire a diminué du fait des conditions ajoutées dans le CountVectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Numérique continu : TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons décidé de créer 2 objets tfidfVectorizer : un avec les stopwords et un sans les stopwords. En effet, les mots entrés dans les stopwords peuvent être importants pour interpréter la polarité d'un avis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Avec stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_tfidf_sw = TfidfVectorizer(min_df=5, stop_words=sw, ngram_range=(1,2)).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23492, 5507)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect_count.get_feature_names_out()), len(vect_tfidf_sw.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized_tfidf_sw = vect_tfidf_sw.transform(X_train)\n",
    "X_valid_vectorized_tfidf_sw = vect_tfidf_sw.transform(X_valid)\n",
    "X_test_vectorized_tfidf_sw = vect_tfidf_sw.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Sans stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_tfidf = TfidfVectorizer(min_df=5).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23492, 4336)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect_count.get_feature_names_out()), len(vect_tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectorized_tfidf = vect_tfidf.transform(X_train)\n",
    "X_valid_vectorized_tfidf = vect_tfidf.transform(X_valid)\n",
    "X_test_vectorized_tfidf = vect_tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Classification sans les stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Modèles de référence faibles (*weak baselines*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. Choix alétaoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_prop_class = DummyClassifier(strategy='stratified').fit(X_train_vectorized_tfidf,\n",
    "                                                               y_train)\n",
    "predictions_valid = random_prop_class.predict(X_valid_vectorized_tfidf)\n",
    "conf_mat = confusion_matrix(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12  30  77]\n",
      " [ 38  76 228]\n",
      " [ 90 252 805]]\n"
     ]
    }
   ],
   "source": [
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5553482587064676"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1,  1, ...,  0,  0,  0])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_uniform = DummyClassifier(strategy='uniform').fit(X_train_vectorized_tfidf,\n",
    "                                                         y_train)\n",
    "predictions_valid = random_uniform.predict(X_valid_vectorized_tfidf)\n",
    "predictions_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 39  34  46]\n",
      " [115 107 120]\n",
      " [400 372 375]]\n"
     ]
    }
   ],
   "source": [
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3240049751243781"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.07      0.33      0.12       119\n",
      "           0       0.21      0.31      0.25       342\n",
      "           1       0.69      0.33      0.44      1147\n",
      "\n",
      "    accuracy                           0.32      1608\n",
      "   macro avg       0.32      0.32      0.27      1608\n",
      "weighted avg       0.54      0.32      0.38      1608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2. Prédiction constante de la classe majoritaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_reviews</th>\n",
       "      <th>pourcentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6658</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2129</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>858</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nb_reviews  pourcentage\n",
       "class                         \n",
       " 1           6658         0.69\n",
       " 0           2129         0.22\n",
       "-1            858         0.09"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarity_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion modèles de référence faibles\n",
    "Ici, l'accuray des modèles n'est vraiment pas très bonne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Classifieur bayésien naïf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nb = MultinomialNB().fit(X_train_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_nb.predict(X_valid_vectorized_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7139303482587065"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le modèle prédit correctement 71.33% des avis du jeu de données de validation.\n",
    "\n",
    "On affiche la matrice de confusion pour le jeu de données de validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.01      0.02       119\n",
      "           0       0.00      0.00      0.00       342\n",
      "           1       0.71      1.00      0.83      1147\n",
      "\n",
      "    accuracy                           0.71      1608\n",
      "   macro avg       0.57      0.34      0.28      1608\n",
      "weighted avg       0.58      0.71      0.60      1608\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/margauxbailleul/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Régression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1. Premier modèle de régression logistique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression(multi_class='multinomial', solver='lbfgs',\n",
    "                              max_iter=200).fit(X_train_vectorized_count, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_valid = model_lr.predict(X_valid_vectorized_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6716417910447762"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre modèle de régression logistique prédit correctement 67.16% des avis du jeu de données de validation.\n",
    "\n",
    "On affiche la matrice de confusion pour le jeu de données de validation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.26      0.12      0.16       119\n",
      "           0       0.29      0.18      0.22       342\n",
      "           1       0.75      0.88      0.81      1147\n",
      "\n",
      "    accuracy                           0.67      1608\n",
      "   macro avg       0.43      0.39      0.40      1608\n",
      "weighted avg       0.61      0.67      0.63      1608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association des mots avec les classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_n_strongly_associated_features(vectoriser, model, n):\n",
    "    feature_names = np.array(vectoriser.get_feature_names_out())\n",
    "\n",
    "    for i in range(3):\n",
    "        class_name = model.classes_[i]\n",
    "        print(\"CLASSE {}\".format(class_name))\n",
    "        idx_coefs_sorted = model.coef_[i].argsort() # ordre croissant\n",
    "        print(\"Les dix variables ayant l'association négative la plus forte \" + \n",
    "              \"avec la classe {} :\\n{}\\n\".format(class_name,\n",
    "                                                 feature_names[idx_coefs_sorted[:n]]))\n",
    "        idx_coefs_sorted = idx_coefs_sorted[::-1] # ordre décroissant\n",
    "        print(\"Les dix variables ayant l'association positive la plus forte \" +\n",
    "              \"avec la classe {} :\\n{}\\n\"\n",
    "              .format(class_name,\n",
    "                      feature_names[idx_coefs_sorted[:n]]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSE -1\n",
      "Les dix variables ayant l'association négative la plus forte avec la classe -1 :\n",
      "['avoue' 'vous' 'coeur' 'toute' 'peux' 'laisse' 'adoré' 'originale'\n",
      " 'aventure' 'quel']\n",
      "\n",
      "Les dix variables ayant l'association positive la plus forte avec la classe -1 :\n",
      "['déception' 'bof' 'prénoms' 'malheureusement' 'opération' 'melancholia'\n",
      " 'pffff' 'abandon' 'vaincus' 'voulu']\n",
      "\n",
      "\n",
      "CLASSE 0\n",
      "Les dix variables ayant l'association négative la plus forte avec la classe 0 :\n",
      "['collection' 'poésie' 'tellement' 'écrire' 'agit' 'excellent' 'héroïne'\n",
      " 'couleur' 'sera' 'couverture']\n",
      "\n",
      "Les dix variables ayant l'association positive la plus forte avec la classe 0 :\n",
      "['douce' 'tragédie' 'sympathique' 'direction' 'voulait' 'épouse' 'belge'\n",
      " 'choisit' 'points' 'initiatique']\n",
      "\n",
      "\n",
      "CLASSE 1\n",
      "Les dix variables ayant l'association négative la plus forte avec la classe 1 :\n",
      "['déception' 'loup' 'déçue' 'douce' 'adhéré' 'netgalleyfrance' 'trouvé'\n",
      " 'points' 'soient' 'tomes']\n",
      "\n",
      "Les dix variables ayant l'association positive la plus forte avec la classe 1 :\n",
      "['magnifique' 'coeur' 'couleur' 'excellent' 'merveille' 'adoré' 'quel'\n",
      " 'fan' 'simplement' 'découverte']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_n_strongly_associated_features(vect_count, model_lr, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir qu'il y a le mot \"deçue\" dans la classe 1 mais cela dépend du contexte. L'avis a pu être \"je ne suis pas du tout déçue\" et donc la polarité est positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir quel le résultat est très logique. En effet, si nous prenons l'exemple de la classe 1, nous pouvons voir que les mots les moins probables d'y être associés sont par exemple \"déception\" ou \"déçue\", tandis qu eles mots étant le plus probable d'être cités sont \"magnifique\" ou encore \"excellent\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2. Deuxième modèle de régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(multi_class='multinomial',\n",
    "                              solver='lbfgs').fit(X_train_vectorized_tfidf, y_train)\n",
    "predictions_valid = model_lr.predict(X_valid_vectorized_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7120646766169154"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La performance est meilleure que le premier modèle de régression logistique. En effet, le modèle prédit correctement 71.21% des avis du jeu de données de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.60      0.03      0.05       119\n",
      "           0       0.37      0.05      0.09       342\n",
      "           1       0.72      0.98      0.83      1147\n",
      "\n",
      "    accuracy                           0.71      1608\n",
      "   macro avg       0.56      0.35      0.32      1608\n",
      "weighted avg       0.64      0.71      0.62      1608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 5251 is out of bounds for axis 0 with size 4336",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[116], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m idx_tfidf_sorted \u001b[38;5;241m=\u001b[39m X_train_vectorized_tfidf\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mtoarray()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margsort()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# print(\"TF-IDF le moins élevé : {}\".format(feature_names[idx_tfidf_sorted[:10]]))\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# print(\"TF-IDF le plus élevé : {}\".format(feature_names[idx_tfidf_sorted[:-11:-1]]))\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(feature_names[idx_tfidf_sorted[:\u001b[38;5;241m10\u001b[39m]])\n",
      "\u001b[1;31mIndexError\u001b[0m: index 5251 is out of bounds for axis 0 with size 4336"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect_tfidf.get_feature_names_out())\n",
    "idx_tfidf_sorted = X_train_vectorized_tfidf.max(0).toarray()[0].argsort()\n",
    "# print(\"TF-IDF le moins élevé : {}\".format(feature_names[idx_tfidf_sorted[:10]]))\n",
    "# print(\"TF-IDF le plus élevé : {}\".format(feature_names[idx_tfidf_sorted[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3. Troisième modèle de régression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous créons un modèle de régression logistique avec le vectoriseur à unigrammes et bigrammes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(multi_class='multinomial', \n",
    "                              solver='lbfgs',\n",
    "                              max_iter=500).fit(X_train_vectorized_count_bigrams, \n",
    "                                                y_train)\n",
    "predictions_valid = model_lr.predict(X_valid_vectorized_count_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6741293532338308"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce modèle prédit correctement 67.41% des avis du jeu de données de validation.\\\n",
    "Sa performance est moins bonne que le deuxième modèle de régression logistique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.28      0.13      0.17       119\n",
      "           0       0.35      0.25      0.29       342\n",
      "           1       0.75      0.86      0.80      1147\n",
      "\n",
      "    accuracy                           0.67      1608\n",
      "   macro avg       0.46      0.41      0.42      1608\n",
      "weighted avg       0.63      0.67      0.65      1608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSE -1\n",
      "Les dix variables ayant l'association négative la plus forte avec la classe -1 :\n",
      "['vous' 'et bien' 'aventure' 'avoue' 'toute' 'pour ce' 'originale'\n",
      " 'ce service' 'si je' 'coeur']\n",
      "\n",
      "Les dix variables ayant l'association positive la plus forte avec la classe -1 :\n",
      "['déception' 'tomes' 'jolies' 'opération' 'prénoms' 'garou' 'éviter'\n",
      " 'mauvais' 'pauvre' 'moyen']\n",
      "\n",
      "\n",
      "CLASSE 0\n",
      "Les dix variables ayant l'association négative la plus forte avec la classe 0 :\n",
      "['sa vie' 'après avoir' 'une enquête' 'on se' 'avec une' 'sera' 'héroïne'\n",
      " 'qui lui' 'tellement' 'tout en']\n",
      "\n",
      "Les dix variables ayant l'association positive la plus forte avec la classe 0 :\n",
      "['douce' 'tragédie' 'sympathique' 'et qu' 'tout un' 'et bien' 'contient'\n",
      " 'en premier' 'voulait' 'racontant']\n",
      "\n",
      "\n",
      "CLASSE 1\n",
      "Les dix variables ayant l'association négative la plus forte avec la classe 1 :\n",
      "['déception' 'tomes' 'et qu' 'douce' 'tragédie' 'loup' 'sans plus'\n",
      " 'présente' 'déçue' 'points']\n",
      "\n",
      "Les dix variables ayant l'association positive la plus forte avec la classe 1 :\n",
      "['quel' 'magnifique' 'coeur' 'coup' 'ceux qui' 'un très' 'couleur'\n",
      " 'noir et' 'mon avis' 'bouleversant']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_n_strongly_associated_features(vect_count_bigrams, model_lr, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a plus d'erreur dans ce modèle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_svm = SVC(kernel='linear', \n",
    "                C=0.1).fit(X_train_vectorized_count_bigrams, \n",
    "                           y_train)\n",
    "\n",
    "predictions_valid = model_svm.predict(X_valid_vectorized_count_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6735074626865671"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.21      0.13      0.16       119\n",
      "           0       0.32      0.15      0.21       342\n",
      "           1       0.74      0.88      0.81      1147\n",
      "\n",
      "    accuracy                           0.67      1608\n",
      "   macro avg       0.42      0.39      0.39      1608\n",
      "weighted avg       0.61      0.67      0.63      1608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Classification avec les stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, nous n'allons pas reproduire tous les tests de modèles essayés précdemment. Nous allons simplement tester les 2 modèles avec la meilleure accuracy obtenue, pour voir si le fait de supprimer les stopwords a un impact sur notre modèle. \\\n",
    "Nous allons donc utiliser le deuxième modèle de régression logistique ainsi que celui avec le classifieur baïésien naïf, dont les deux accuracy sont à 71% environ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Classifieur naïf baïésien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nb = MultinomialNB().fit(X_train_vectorized_tfidf_sw, y_train)\n",
    "predictions_valid = model_nb.predict(X_valid_vectorized_tfidf_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclure pour ici mais j'ai pas les scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Deuxième modèle de régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression(multi_class='multinomial',\n",
    "                              solver='lbfgs').fit(X_train_vectorized_tfidf_sw, y_train)\n",
    "predictions_valid = model_lr.predict(X_valid_vectorized_tfidf_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_valid, predictions_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclure ici mais pareil j'ai pas les scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Est-ce qu'on fait un test en + avec bigram et trigram ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À VOIR :\n",
    "\n",
    "- est ce qu'on fait aussi les tests avec les bigrams et tigrams (diminution du nb de mots) ? \n",
    "- est-ce qu'on prend reader_review pour les train et les test ou est-ce qu'on prend la colonne des entités nommées ? ou une autre colonne ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons donc dire que le meilleur modèle est celui avec/sans les stopwords et celui qui utilise ??? (mettre meilleur modèle)\n",
    "\n",
    "Cependant, notre matrice de confusion est possiblement biaisée. En effet, certains de nos avis sont des \"résumés\" des livres, et ils on été classés dans la base de donnée comme non neutres. \n",
    "\n",
    "On a testé avec les bigram et trigram car intéressant dans notre cas \n",
    "\n",
    "On a pris la colonne avec les entités nommées car cela ne nous apporte rien de savoir le nom ??\n",
    "\n",
    "Si on teste avec une autre colonne : expliquer pourquoi "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
